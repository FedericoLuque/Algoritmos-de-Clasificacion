{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228},{"sourceId":975216,"sourceType":"datasetVersion","datasetId":532277},{"sourceId":3047725,"sourceType":"datasetVersion","datasetId":1866301},{"sourceId":5651459,"sourceType":"datasetVersion","datasetId":3248517}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-01T20:56:39.693573Z","iopub.execute_input":"2025-03-01T20:56:39.693986Z","iopub.status.idle":"2025-03-01T20:56:39.708276Z","shell.execute_reply.started":"2025-03-01T20:56:39.693948Z","shell.execute_reply":"2025-03-01T20:56:39.706593Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Guardar cada Modelo con la métrica correspondiente\ndef guardarResultados(model, a,b,c,d):\n  Modelo.append(model)\n  exactitud.append(round(a, 3))\n  f1_score.append(round(b, 3))\n  sensibilidad.append(round(c, 3))\n  precision.append(round(d, 3))\n\n# Función para mostar el resultado de las métricas\ndef mostrarMetricas(modelo,metrica,valor_metrica_entrenamiento,valor_metrica_testeo):\n    print(\"{} : {} en los datos de entrenamiento: {:.3f}\".format(modelo, metrica, valor_metrica_entrenamiento))\n    print(\"{} : {} en los datos de testeo: {:.3f}\".format(modelo, metrica, valor_metrica_testeo))\n    print()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:56:39.710503Z","iopub.execute_input":"2025-03-01T20:56:39.710841Z","iopub.status.idle":"2025-03-01T20:56:39.736052Z","shell.execute_reply.started":"2025-03-01T20:56:39.710815Z","shell.execute_reply":"2025-03-01T20:56:39.734522Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"phishing = pd.read_csv(\"/kaggle/input/phishing-website-detector/phishing.csv\")\n\nwine = pd.read_csv(\"/kaggle/input/wine-quality-dataset/WineQT.csv\")\n\ncancer = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-diagnostic-dataset/brca.csv\")\n\ndiabetes = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:56:39.738570Z","iopub.execute_input":"2025-03-01T20:56:39.738916Z","iopub.status.idle":"2025-03-01T20:56:39.826666Z","shell.execute_reply.started":"2025-03-01T20:56:39.738888Z","shell.execute_reply":"2025-03-01T20:56:39.825171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Support Vector Machine (SVM)\n\nEl algoritmo Support Vector Machine (SVM) es un modelo de aprendizaje supervisado utilizado principalmente para clasificación y regresión. Su objetivo es encontrar un hiperplano óptimo que separe los datos en diferentes clases con el mayor margen posible.\n\nUn hiperplano óptimo es la frontera de decisión que mejor separa las clases en un problema de clasificación utilizando Support Vector Machines (SVM). Su principal característica es que maximiza el margen entre las clases, es decir, la distancia entre el hiperplano y los puntos de datos más cercanos de cada clase, llamados vectores de soporte.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset SVC\n\nEl dataset consiste en un grupo de caracteristicas que tienen las URL's para determinar si son enlaces maliciosos o no. \nLa variable objetivo es \"class\", con 1 para enlaces maliciosos y -1 para enlaces legitimos.","metadata":{}},{"cell_type":"code","source":"phishing.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:56:39.829001Z","iopub.execute_input":"2025-03-01T20:56:39.829490Z","iopub.status.idle":"2025-03-01T20:56:39.855389Z","shell.execute_reply.started":"2025-03-01T20:56:39.829453Z","shell.execute_reply":"2025-03-01T20:56:39.852684Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Eliminamos la columna Index, que es unidentificador y no nos sirve\n\nphishing = phishing.drop(['Index'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:56:39.857389Z","iopub.execute_input":"2025-03-01T20:56:39.857862Z","iopub.status.idle":"2025-03-01T20:56:39.882222Z","shell.execute_reply.started":"2025-03-01T20:56:39.857820Z","shell.execute_reply":"2025-03-01T20:56:39.880812Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sin hiperparametros","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport random\n\nX = phishing.drop([\"class\"],axis =1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC()\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:56:39.883613Z","iopub.execute_input":"2025-03-01T20:56:39.884031Z","iopub.status.idle":"2025-03-01T20:57:00.637339Z","shell.execute_reply.started":"2025-03-01T20:56:39.883988Z","shell.execute_reply":"2025-03-01T20:57:00.636165Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import cohen_kappa_score\n\n# Calculamos las métricas\nexactitud_train_SVC = metrics.accuracy_score(y_train, y_train_SVC)\nexactitud_test_SVC = metrics.accuracy_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"exactitud\", exactitud_train_SVC, exactitud_test_SVC)\n\nf1_score_train_SVC = metrics.f1_score(y_train, y_train_SVC)\nf1_score_test_SVC = metrics.f1_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"f1_score\", f1_score_train_SVC, f1_score_test_SVC)\n\nsensibilidad_train_SVC = metrics.recall_score(y_train, y_train_SVC)\nsensibilidad_test_SVC = metrics.recall_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"sensibilidad\", sensibilidad_train_SVC, sensibilidad_test_SVC)\n\nprecision_train_SVC = metrics.precision_score(y_train, y_train_SVC)\nprecision_test_SVC = metrics.precision_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"precision\", precision_train_SVC, precision_test_SVC)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.638476Z","iopub.execute_input":"2025-03-01T20:57:00.639064Z","iopub.status.idle":"2025-03-01T20:57:00.679676Z","shell.execute_reply.started":"2025-03-01T20:57:00.639034Z","shell.execute_reply":"2025-03-01T20:57:00.678584Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.683114Z","iopub.execute_input":"2025-03-01T20:57:00.683471Z","iopub.status.idle":"2025-03-01T20:57:00.719622Z","shell.execute_reply.started":"2025-03-01T20:57:00.683444Z","shell.execute_reply":"2025-03-01T20:57:00.718242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Análisis de resultados\n\nEl modelo tiene un buen resultado con un 95% de precisión general. Además, muestra un buen equilibrio entre precisión y recall en ambas clases. No hay un sesgo fuerte hacia ninguna de las clases.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino SVC\n\nEste conjunto de datos está relacionado con las variantes tintas del vino portugués \"Vinho Verde\". El conjunto de datos describe la cantidad de diversos productos químicos presentes en el vino y su efecto en su calidad.","metadata":{}},{"cell_type":"code","source":"wine.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.721352Z","iopub.execute_input":"2025-03-01T20:57:00.721641Z","iopub.status.idle":"2025-03-01T20:57:00.736000Z","shell.execute_reply.started":"2025-03-01T20:57:00.721619Z","shell.execute_reply":"2025-03-01T20:57:00.734600Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dataset con todos los valores numericos y sin nulos","metadata":{}},{"cell_type":"code","source":"wine['quality'].unique()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.737116Z","iopub.execute_input":"2025-03-01T20:57:00.737473Z","iopub.status.idle":"2025-03-01T20:57:00.763807Z","shell.execute_reply.started":"2025-03-01T20:57:00.737447Z","shell.execute_reply":"2025-03-01T20:57:00.762764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convertimos los valores 3,4 y 5 en 0 (mala calidad) y 6,7 y 8 en 1 (buena calidad)\n\nwine['quality'] = wine['quality'].apply(lambda x: 1 if x in [6, 7, 8] else 0)\nwine = wine.drop(['Id'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.764719Z","iopub.execute_input":"2025-03-01T20:57:00.765040Z","iopub.status.idle":"2025-03-01T20:57:00.786921Z","shell.execute_reply.started":"2025-03-01T20:57:00.765014Z","shell.execute_reply":"2025-03-01T20:57:00.785429Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sin hiperparametros","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow as tf\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\nX = wine.drop([\"quality\"],axis =1)\ny = wine[\"quality\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC()\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.788139Z","iopub.execute_input":"2025-03-01T20:57:00.788704Z","iopub.status.idle":"2025-03-01T20:57:00.900111Z","shell.execute_reply.started":"2025-03-01T20:57:00.788652Z","shell.execute_reply":"2025-03-01T20:57:00.898826Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\n# Calculamos las métricas\nexactitud_train_SVC = metrics.accuracy_score(y_train, y_train_SVC)\nexactitud_test_SVC = metrics.accuracy_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"exactitud\", exactitud_train_SVC, exactitud_test_SVC)\n\nf1_score_train_SVC = metrics.f1_score(y_train, y_train_SVC)\nf1_score_test_SVC = metrics.f1_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"f1_score\", f1_score_train_SVC, f1_score_test_SVC)\n\nsensibilidad_train_SVC = metrics.recall_score(y_train, y_train_SVC)\nsensibilidad_test_SVC = metrics.recall_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"sensibilidad\", sensibilidad_train_SVC, sensibilidad_test_SVC)\n\nprecision_train_SVC = metrics.precision_score(y_train, y_train_SVC)\nprecision_test_SVC = metrics.precision_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"precision\", precision_train_SVC, precision_test_SVC)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.901272Z","iopub.execute_input":"2025-03-01T20:57:00.901627Z","iopub.status.idle":"2025-03-01T20:57:00.929864Z","shell.execute_reply.started":"2025-03-01T20:57:00.901602Z","shell.execute_reply":"2025-03-01T20:57:00.928784Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.931011Z","iopub.execute_input":"2025-03-01T20:57:00.931395Z","iopub.status.idle":"2025-03-01T20:57:00.952907Z","shell.execute_reply.started":"2025-03-01T20:57:00.931366Z","shell.execute_reply":"2025-03-01T20:57:00.951429Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analisis de resultados\n\nEste modelo tiene un rendimiento significativamente peor que el primero. Mientras que el primer modelo tiene una precisión y recall equilibrados en torno al 95%, este modelo tiene una precisión general mucho más baja (especialmente para la clase 0, con un recall del 39%), lo que indica que está fallando en detectar correctamente una de las clases. Además, su exactitud global es del 68%, bastante inferior al 95% del primero.\n\nEsto puede deberse a que este modelo tiene menos variables y registros con los que trabajar y quizás a la simplificacion que hemos realizado de su variable objetivo.","metadata":{}},{"cell_type":"markdown","source":"## Diagnóstico de Cáncer de Mama SVC\n\nCaracterísticas de la biopsia para la clasificación de 569 masas mamarias malignas (cancerosas) y benignas (no cancerosas).","metadata":{}},{"cell_type":"code","source":"cancer.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.954212Z","iopub.execute_input":"2025-03-01T20:57:00.954611Z","iopub.status.idle":"2025-03-01T20:57:00.971156Z","shell.execute_reply.started":"2025-03-01T20:57:00.954582Z","shell.execute_reply":"2025-03-01T20:57:00.969959Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cancer.drop(['Unnamed: 0'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:00.972339Z","iopub.execute_input":"2025-03-01T20:57:00.972717Z","iopub.status.idle":"2025-03-01T20:57:00.992822Z","shell.execute_reply.started":"2025-03-01T20:57:00.972686Z","shell.execute_reply":"2025-03-01T20:57:00.991524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dataset con valores numericos y sin valores nulos.\nExcepto en la variable objetivo.","metadata":{}},{"cell_type":"code","source":"cancer['y'].unique()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:00.994397Z","iopub.execute_input":"2025-03-01T20:57:00.994739Z","iopub.status.idle":"2025-03-01T20:57:01.023659Z","shell.execute_reply.started":"2025-03-01T20:57:00.994710Z","shell.execute_reply":"2025-03-01T20:57:01.022510Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Convertimos B en 0 (sano) y M en 1 (enfermo)","metadata":{}},{"cell_type":"code","source":"cancer['y'] = cancer['y'].map({'B': 0, 'M': 1})","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.024710Z","iopub.execute_input":"2025-03-01T20:57:01.025036Z","iopub.status.idle":"2025-03-01T20:57:01.047302Z","shell.execute_reply.started":"2025-03-01T20:57:01.025008Z","shell.execute_reply":"2025-03-01T20:57:01.045967Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sin hiperparametros","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow as tf\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\nX = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC()\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.048407Z","iopub.execute_input":"2025-03-01T20:57:01.048781Z","iopub.status.idle":"2025-03-01T20:57:01.089611Z","shell.execute_reply.started":"2025-03-01T20:57:01.048740Z","shell.execute_reply":"2025-03-01T20:57:01.088587Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\n# Calculamos las métricas\nexactitud_train_SVC = metrics.accuracy_score(y_train, y_train_SVC)\nexactitud_test_SVC = metrics.accuracy_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"exactitud\", exactitud_train_SVC, exactitud_test_SVC)\n\nf1_score_train_SVC = metrics.f1_score(y_train, y_train_SVC)\nf1_score_test_SVC = metrics.f1_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"f1_score\", f1_score_train_SVC, f1_score_test_SVC)\n\nsensibilidad_train_SVC = metrics.recall_score(y_train, y_train_SVC)\nsensibilidad_test_SVC = metrics.recall_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"sensibilidad\", sensibilidad_train_SVC, sensibilidad_test_SVC)\n\nprecision_train_SVC = metrics.precision_score(y_train, y_train_SVC)\nprecision_test_SVC = metrics.precision_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"precision\", precision_train_SVC, precision_test_SVC)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.090679Z","iopub.execute_input":"2025-03-01T20:57:01.090932Z","iopub.status.idle":"2025-03-01T20:57:01.122244Z","shell.execute_reply.started":"2025-03-01T20:57:01.090912Z","shell.execute_reply":"2025-03-01T20:57:01.121032Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.123400Z","iopub.execute_input":"2025-03-01T20:57:01.123691Z","iopub.status.idle":"2025-03-01T20:57:01.146633Z","shell.execute_reply.started":"2025-03-01T20:57:01.123667Z","shell.execute_reply":"2025-03-01T20:57:01.145346Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analisis de resultados\n\nEste modelo tiene el mejor rendimiento de los tres, con una precisión y recall cercanos al 100%, lo que indica que casi no comete errores. Sin embargo, su dataset es mucho más pequeño (114 muestras frente a 2211 y 229 en los otros modelos), por lo que su desempeño podría no generalizarse bien a un conjunto de datos más grande.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes SVC\n\nEste conjunto de datos es originario del Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales. El objetivo del conjunto de datos es predecir a nivel de diagnóstico si un paciente tiene o no diabetes, basándose en ciertas mediciones de diagnóstico incluidas en el conjunto de datos.","metadata":{}},{"cell_type":"code","source":"diabetes.info()","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.148097Z","iopub.execute_input":"2025-03-01T20:57:01.148540Z","iopub.status.idle":"2025-03-01T20:57:01.163244Z","shell.execute_reply.started":"2025-03-01T20:57:01.148502Z","shell.execute_reply":"2025-03-01T20:57:01.162113Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dataset de valores numericos sin valores nulos.","metadata":{}},{"cell_type":"markdown","source":"### Sin hiperparametros","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\n\nX = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC()\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.169666Z","iopub.execute_input":"2025-03-01T20:57:01.170051Z","iopub.status.idle":"2025-03-01T20:57:01.231174Z","shell.execute_reply.started":"2025-03-01T20:57:01.170020Z","shell.execute_reply":"2025-03-01T20:57:01.230044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\n# Calculamos las métricas\nexactitud_train_SVC = metrics.accuracy_score(y_train, y_train_SVC)\nexactitud_test_SVC = metrics.accuracy_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"exactitud\", exactitud_train_SVC, exactitud_test_SVC)\n\nf1_score_train_SVC = metrics.f1_score(y_train, y_train_SVC)\nf1_score_test_SVC = metrics.f1_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"f1_score\", f1_score_train_SVC, f1_score_test_SVC)\n\nsensibilidad_train_SVC = metrics.recall_score(y_train, y_train_SVC)\nsensibilidad_test_SVC = metrics.recall_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"sensibilidad\", sensibilidad_train_SVC, sensibilidad_test_SVC)\n\nprecision_train_SVC = metrics.precision_score(y_train, y_train_SVC)\nprecision_test_SVC = metrics.precision_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"precision\", precision_train_SVC, precision_test_SVC)\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.234789Z","iopub.execute_input":"2025-03-01T20:57:01.235149Z","iopub.status.idle":"2025-03-01T20:57:01.267018Z","shell.execute_reply.started":"2025-03-01T20:57:01.235121Z","shell.execute_reply":"2025-03-01T20:57:01.265766Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.268437Z","iopub.execute_input":"2025-03-01T20:57:01.268856Z","iopub.status.idle":"2025-03-01T20:57:01.291750Z","shell.execute_reply.started":"2025-03-01T20:57:01.268816Z","shell.execute_reply":"2025-03-01T20:57:01.290499Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analisis de resultados\n\nEl cuarto modelo tiene un rendimiento intermedio entre el primero y el segundo. Es mejor que el segundo modelo (64% de accuracy) pero sigue estando por debajo del primero (95%) y del tercero (98%).\n\nTiene un rendimiento aceptable, pero su baja capacidad para detectar correctamente la clase 1 (recall del 56%) puede ser un problema.","metadata":{}},{"cell_type":"markdown","source":"## Análisis Comparativo del Algoritmo en los Diferentes Datasets\n\n| **Dataset**              | **Accuracy** | **F1-Score (Clase 1)** | **AUC**  | **Cohen’s Kappa** |\n|--------------------------|-------------|------------------------|----------|-------------------|\n| **Detección de phishing** | 0.95        | 0.96                   | 0.95     | 0.90              |\n| **Calidad del vino**      | 0.68        | 0.76                   | 0.61     | 0.23              |\n| **Cáncer de mama**        | 0.93        | 0.90                   | 0.90     | 0.82              |\n| **Detección de diabetes** | 0.77        | 0.63                   | 0.70     | 0.44              |\n\n\n- SVC muestra un buen rendimiento en problemas de clasificación binaria bien definidos, como la detección de phishing y cáncer de mama.\n- Para problemas más complejos o con un alto desbalance entre clases (como la calidad del vino y diabetes), el modelo SVC tiene dificultades, especialmente en la predicción de la clase positiva (diabetes en este caso).","metadata":{}},{"cell_type":"markdown","source":"## Ajuste de Hiperparámetros\n\n- **C (Parámetro de regularización):** Controla el equilibrio entre un margen más grande y minimizar los errores de clasificación.\n\n    - **Valores bajos** → Mayor margen, más tolerancia a errores (puede subajustar).\n    - **Valores altos** → Menor margen, menos tolerancia a errores (puede sobreajustar).\n\n---\n\n- **kernel (Tipo de núcleo o función de transformación):** Define cómo se transforman los datos en un espacio de mayor dimensión para hacerlos separables.\n\n    - **\"linear\"** → Para datos linealmente separables.\n    - **\"sigmoid\"** → Similar a una red neuronal.\n    - **\"poly\"** → Polinómico, útil para relaciones no lineales.\n        - **degree** → Define el grado del polinomio cuando se usa un kernel polinómico. (Valores comunes: 2 o 3).\n    - **\"rbf\"** → Función de base radial (gaussiana), muy usada en datos complejos.\n        - **gamma** (poly y rbf) → Controla la influencia de cada punto de entrenamiento.\n","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset SVC con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"],axis =1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=0.1, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:01.292842Z","iopub.execute_input":"2025-03-01T20:57:01.293176Z","iopub.status.idle":"2025-03-01T20:57:02.785195Z","shell.execute_reply.started":"2025-03-01T20:57:01.293147Z","shell.execute_reply":"2025-03-01T20:57:02.783804Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\n# Calculamos las métricas\nexactitud_train_SVC = metrics.accuracy_score(y_train, y_train_SVC)\nexactitud_test_SVC = metrics.accuracy_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"exactitud\", exactitud_train_SVC, exactitud_test_SVC)\n\nf1_score_train_SVC = metrics.f1_score(y_train, y_train_SVC)\nf1_score_test_SVC = metrics.f1_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"f1_score\", f1_score_train_SVC, f1_score_test_SVC)\n\nsensibilidad_train_SVC = metrics.recall_score(y_train, y_train_SVC)\nsensibilidad_test_SVC = metrics.recall_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"sensibilidad\", sensibilidad_train_SVC, sensibilidad_test_SVC)\n\nprecision_train_SVC = metrics.precision_score(y_train, y_train_SVC)\nprecision_test_SVC = metrics.precision_score(y_test, y_test_SVC)\n\nmostrarMetricas(modelo, \"precision\", precision_train_SVC, precision_test_SVC)\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:02.786410Z","iopub.execute_input":"2025-03-01T20:57:02.786942Z","iopub.status.idle":"2025-03-01T20:57:02.849274Z","shell.execute_reply.started":"2025-03-01T20:57:02.786893Z","shell.execute_reply":"2025-03-01T20:57:02.847965Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:02.850261Z","iopub.execute_input":"2025-03-01T20:57:02.850600Z","iopub.status.idle":"2025-03-01T20:57:02.870611Z","shell.execute_reply.started":"2025-03-01T20:57:02.850575Z","shell.execute_reply":"2025-03-01T20:57:02.869164Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sin ajustar hiperparámetros parece estar funcionando mejor, lo que sugiere que el C=0.1 en el SVM puede estar penalizando demasiado los errores y generando un margen excesivamente amplio. Vamos a probar a aumentar C para ver si mejora la precisión sin perder generalización.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset SVC con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"],axis =1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=10, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:02.871659Z","iopub.execute_input":"2025-03-01T20:57:02.871983Z","iopub.status.idle":"2025-03-01T20:57:09.543881Z","shell.execute_reply.started":"2025-03-01T20:57:02.871948Z","shell.execute_reply":"2025-03-01T20:57:09.542500Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El aumento de C ha tenido un efecto positivo en la clasificación de la clase 1, con mejoras en precision y recall. Sin embargo, la accuracy general no ha cambiado respecto a C=0.1, lo que sugiere que el modelo sigue funcionando de manera similar.\n\nVamos a probar este modelo, que es el que mejor resultado da, con valores aleatorios.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"UsingIP\": np.random.choice([0, 1], 10),\n    \"LongURL\": np.random.choice([0, 1], 10),\n    \"ShortURL\": np.random.choice([0, 1], 10),\n    \"Symbol@\": np.random.choice([0, 1], 10),\n    \"Redirecting//\": np.random.choice([0, 1], 10),\n    \"PrefixSuffix-\": np.random.choice([0, 1], 10),\n    \"SubDomains\": np.random.choice([0, 1], 10),\n    \"HTTPS\": np.random.choice([0, 1], 10),\n    \"DomainRegLen\": np.random.randint(5, 15, 10),\n    \"Favicon\": np.random.choice([0, 1], 10),\n    \"NonStdPort\": np.random.choice([0, 1], 10),\n    \"HTTPSDomainURL\": np.random.choice([0, 1], 10),\n    \"RequestURL\": np.random.choice([0, 1], 10),\n    \"AnchorURL\": np.random.choice([0, 1], 10),\n    \"LinksInScriptTags\": np.random.choice([0, 1], 10),\n    \"ServerFormHandler\": np.random.choice([0, 1], 10),\n    \"InfoEmail\": np.random.choice([0, 1], 10),\n    \"AbnormalURL\": np.random.choice([0, 1], 10),\n    \"WebsiteForwarding\": np.random.choice([0, 1], 10),\n    \"StatusBarCust\": np.random.choice([0, 1], 10),\n    \"DisableRightClick\": np.random.choice([0, 1], 10),\n    \"UsingPopupWindow\": np.random.choice([0, 1], 10),\n    \"IframeRedirection\": np.random.choice([0, 1], 10),\n    \"AgeofDomain\": np.random.randint(1, 20, 10),\n    \"DNSRecording\": np.random.choice([0, 1], 10),\n    \"WebsiteTraffic\": np.random.randint(1000, 10000, 10),\n    \"PageRank\": np.random.randint(0, 10, 10),\n    \"GoogleIndex\": np.random.randint(0, 1000, 10),\n    \"LinksPointingToPage\": np.random.randint(0, 100, 10),\n    \"StatsReport\": np.random.choice([0, 1], 10),\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = svm_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:09.544778Z","iopub.execute_input":"2025-03-01T20:57:09.545070Z","iopub.status.idle":"2025-03-01T20:57:09.567538Z","shell.execute_reply.started":"2025-03-01T20:57:09.545047Z","shell.execute_reply":"2025-03-01T20:57:09.566400Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phishing dataset SVC con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"],axis =1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=10, kernel=\"rbf\", gamma='scale')\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:09.568684Z","iopub.execute_input":"2025-03-01T20:57:09.569077Z","iopub.status.idle":"2025-03-01T20:57:11.803048Z","shell.execute_reply.started":"2025-03-01T20:57:09.569047Z","shell.execute_reply":"2025-03-01T20:57:11.801774Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El ajuste de gamma='scale' ha tenido un efecto positivo, y el modelo ahora está clasificando con mucha más precisión y eficiencia. La accuracy de 96% es un gran resultado, y parece que hemos encontrado una configuración adecuada para este conjunto de datos.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino SVC con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = wine.drop([\"quality\"],axis =1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=0.1, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:11.804079Z","iopub.execute_input":"2025-03-01T20:57:11.804416Z","iopub.status.idle":"2025-03-01T20:57:11.952640Z","shell.execute_reply.started":"2025-03-01T20:57:11.804389Z","shell.execute_reply":"2025-03-01T20:57:11.951563Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo con los hiperparámetros C=0.1 y kernel=\"linear\" ha mostrado una mejora considerable en comparación con el modelo sin ajustes. En particular, la accuracy ha subido de 64% a 74%, y se ha logrado un mejor balance entre precision y recall en ambas clases.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino SVC con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = wine.drop([\"quality\"],axis =1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=10, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:11.953584Z","iopub.execute_input":"2025-03-01T20:57:11.953891Z","iopub.status.idle":"2025-03-01T20:57:15.534078Z","shell.execute_reply.started":"2025-03-01T20:57:11.953865Z","shell.execute_reply":"2025-03-01T20:57:15.532648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El ajuste de C=10 ha logrado mejorar el modelo, especialmente en la clase 0 (la que antes tenía un recall bajo). El modelo ahora es más equilibrado y parece haber reducido el sesgo hacia la clase 1.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino SVC con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = wine.drop([\"quality\"],axis =1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=10, kernel=\"rbf\", gamma='scale')\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:15.535594Z","iopub.execute_input":"2025-03-01T20:57:15.535915Z","iopub.status.idle":"2025-03-01T20:57:15.648668Z","shell.execute_reply.started":"2025-03-01T20:57:15.535889Z","shell.execute_reply":"2025-03-01T20:57:15.647561Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El cambio a kernel=\"rbf\" y gamma='scale' ha proporcionado algunas mejoras en la precisión y recall de la clase positiva (1), pero también ha causado una leve disminución en la capacidad para identificar correctamente la clase negativa (0). En general, el modelo sigue siendo relativamente equilibrado.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"fixed acidity\": np.random.uniform(6.0, 15.0, 10),\n    \"volatile acidity\": np.random.uniform(0.1, 1.0, 10),\n    \"citric acid\": np.random.uniform(0.0, 1.0, 10),\n    \"residual sugar\": np.random.uniform(0.1, 20.0, 10),\n    \"chlorides\": np.random.uniform(0.01, 0.1, 10),\n    \"free sulfur dioxide\": np.random.randint(1, 50, 10),\n    \"total sulfur dioxide\": np.random.randint(10, 100, 10),\n    \"density\": np.random.uniform(0.98, 1.05, 10),\n    \"pH\": np.random.uniform(2.5, 4.0, 10),\n    \"sulphates\": np.random.uniform(0.3, 1.0, 10),\n    \"alcohol\": np.random.uniform(8.0, 14.0, 10),\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = svm_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:15.649630Z","iopub.execute_input":"2025-03-01T20:57:15.649924Z","iopub.status.idle":"2025-03-01T20:57:15.666077Z","shell.execute_reply.started":"2025-03-01T20:57:15.649902Z","shell.execute_reply":"2025-03-01T20:57:15.665001Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cancer de mama SVC con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=0.1, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:15.667809Z","iopub.execute_input":"2025-03-01T20:57:15.668247Z","iopub.status.idle":"2025-03-01T20:57:15.818758Z","shell.execute_reply.started":"2025-03-01T20:57:15.668202Z","shell.execute_reply":"2025-03-01T20:57:15.817779Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El resultado del modelo sin hiperparametros ya era excepcionalmente bueno. Este al introducir hiperparametros ha dado un resultado perfecto con un 100% de accuracy.\n\nVamos a probar el modelo con datos inventados para realizar predicciones.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"x.radius_mean\": [14.0, 15.5, 13.2, 14.5, 15.0, 13.8, 14.2, 16.1, 15.3, 14.6],\n    \"x.texture_mean\": [19.0, 20.3, 18.5, 17.2, 21.1, 20.0, 18.8, 19.5, 20.2, 19.3],\n    \"x.perimeter_mean\": [85.0, 90.5, 80.3, 84.6, 89.7, 82.1, 86.4, 88.9, 87.5, 85.3],\n    \"x.area_mean\": [500.0, 550.2, 480.5, 510.6, 545.0, 495.0, 520.1, 530.4, 515.3, 505.2],\n    \"x.smoothness_mean\": [0.1, 0.12, 0.09, 0.11, 0.1, 0.08, 0.1, 0.13, 0.12, 0.1],\n    \"x.compactness_mean\": [0.02, 0.03, 0.025, 0.021, 0.03, 0.015, 0.02, 0.03, 0.02, 0.022],\n    \"x.concavity_mean\": [0.05, 0.07, 0.06, 0.055, 0.065, 0.045, 0.05, 0.06, 0.055, 0.05],\n    \"x.concave_pts_mean\": [0.03, 0.035, 0.02, 0.04, 0.03, 0.025, 0.03, 0.03, 0.025, 0.03],\n    \"x.symmetry_mean\": [0.18, 0.2, 0.17, 0.19, 0.18, 0.17, 0.18, 0.21, 0.19, 0.18],\n    \"x.fractal_dim_mean\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.046, 0.047, 0.05, 0.048, 0.05],\n    \"x.radius_se\": [0.03, 0.04, 0.02, 0.03, 0.04, 0.02, 0.03, 0.02, 0.03, 0.04],\n    \"x.texture_se\": [0.04, 0.05, 0.03, 0.04, 0.05, 0.03, 0.04, 0.03, 0.05, 0.04],\n    \"x.perimeter_se\": [0.12, 0.13, 0.1, 0.11, 0.12, 0.09, 0.11, 0.12, 0.1, 0.11],\n    \"x.area_se\": [30.0, 35.2, 28.5, 32.1, 33.5, 29.3, 30.2, 31.6, 32.8, 30.5],\n    \"x.smoothness_se\": [0.002, 0.0025, 0.0018, 0.0022, 0.002, 0.0019, 0.0021, 0.0023, 0.0021, 0.002],\n    \"x.compactness_se\": [0.001, 0.0015, 0.0012, 0.0011, 0.0013, 0.001, 0.0011, 0.0013, 0.0012, 0.0011],\n    \"x.concavity_se\": [0.0025, 0.003, 0.0027, 0.0026, 0.0031, 0.0023, 0.0025, 0.0028, 0.0026, 0.0027],\n    \"x.concave_pts_se\": [0.001, 0.0012, 0.0009, 0.001, 0.0011, 0.0008, 0.001, 0.0011, 0.001, 0.0009],\n    \"x.symmetry_se\": [0.008, 0.01, 0.009, 0.0085, 0.009, 0.008, 0.0085, 0.009, 0.0087, 0.008],\n    \"x.fractal_dim_se\": [0.003, 0.0035, 0.0028, 0.0032, 0.0031, 0.0029, 0.003, 0.0031, 0.0032, 0.003],\n    \"x.radius_worst\": [17.0, 18.5, 16.5, 17.8, 18.3, 16.9, 17.4, 18.7, 17.9, 17.2],\n    \"x.texture_worst\": [22.0, 23.3, 21.8, 22.5, 23.1, 22.3, 21.9, 23.0, 22.8, 22.1],\n    \"x.perimeter_worst\": [110.0, 120.3, 115.2, 113.5, 119.4, 114.6, 117.5, 120.0, 118.2, 115.8],\n    \"x.area_worst\": [800.0, 850.5, 780.3, 800.2, 830.0, 790.1, 810.5, 830.4, 820.2, 800.5],\n    \"x.smoothness_worst\": [0.13, 0.14, 0.12, 0.13, 0.14, 0.13, 0.13, 0.14, 0.13, 0.12],\n    \"x.compactness_worst\": [0.03, 0.035, 0.031, 0.028, 0.032, 0.03, 0.029, 0.031, 0.03, 0.029],\n    \"x.concavity_worst\": [0.07, 0.08, 0.075, 0.071, 0.078, 0.073, 0.074, 0.079, 0.076, 0.075],\n    \"x.concave_pts_worst\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.04, 0.045, 0.06, 0.048, 0.05],\n    \"x.symmetry_worst\": [0.22, 0.23, 0.21, 0.22, 0.23, 0.22, 0.21, 0.22, 0.22, 0.21],\n    \"x.fractal_dim_worst\": [0.05, 0.06, 0.048, 0.05, 0.055, 0.051, 0.052, 0.05, 0.053, 0.054]\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = svm_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:15.819844Z","iopub.execute_input":"2025-03-01T20:57:15.820140Z","iopub.status.idle":"2025-03-01T20:57:15.844246Z","shell.execute_reply.started":"2025-03-01T20:57:15.820117Z","shell.execute_reply":"2025-03-01T20:57:15.842887Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cancer de mama SVC con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=0.1, kernel=\"poly\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:15.845544Z","iopub.execute_input":"2025-03-01T20:57:15.845938Z","iopub.status.idle":"2025-03-01T20:57:15.904884Z","shell.execute_reply.started":"2025-03-01T20:57:15.845894Z","shell.execute_reply":"2025-03-01T20:57:15.903620Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El kernel polinomico ha empeorado bastante los resultados, ya que no es un kernel optimo para datos con relaciones lineales como los de este dataset.","metadata":{}},{"cell_type":"markdown","source":"## Cancer de mama SVC con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=0.1, kernel=\"rbf\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:15.906021Z","iopub.execute_input":"2025-03-01T20:57:15.906446Z","iopub.status.idle":"2025-03-01T20:57:15.952189Z","shell.execute_reply.started":"2025-03-01T20:57:15.906402Z","shell.execute_reply":"2025-03-01T20:57:15.951139Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Despues de obtener un resultado perfecto con el kernel linear, cualquier resultado es peor, aunque estos entran dentro del margen de unos muy buenos resultados.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes SVC con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=0.1, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:15.953362Z","iopub.execute_input":"2025-03-01T20:57:15.953642Z","iopub.status.idle":"2025-03-01T20:57:16.353230Z","shell.execute_reply.started":"2025-03-01T20:57:15.953620Z","shell.execute_reply":"2025-03-01T20:57:16.352015Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Vemos que baja ligeramente la accuracy (de 0.77 a 0.75) con respecto al modelo sin hiperparametros, el recall de la clase 1 pasó de 0.56 a 0.65 y el de la clase 2 de 0.88 a 0.81.\n\nEl modelo ha empeorado levemente sus resultados, por lo que vamos a probar con valores de C mas altos.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes SVC con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=10, kernel=\"linear\")\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:16.354572Z","iopub.execute_input":"2025-03-01T20:57:16.354961Z","iopub.status.idle":"2025-03-01T20:57:48.123683Z","shell.execute_reply.started":"2025-03-01T20:57:16.354923Z","shell.execute_reply":"2025-03-01T20:57:48.122440Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ajustar C=10 ha mejorado la estabilidad del modelo, pero todavía hay margen para optimizar el recall de la clase 1. \n\nEste es el mejor modelo de todos con este dataset, por lo que voy a probar con 10 valores aleatorios con él.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"Pregnancies\": [6, 14, 10, 7, 6, 10, 10, 3, 7, 2],\n    \"Glucose\": [122, 71, 157, 107, 199, 90, 127, 91, 158, 118],\n    \"BloodPressure\": [108, 91, 109, 64, 111, 111, 96, 111, 100, 104],\n    \"SkinThickness\": [12, 46, 16, 30, 18, 48, 27, 13, 34, 23],\n    \"Insulin\": [261, 796, 365, 584, 359, 111, 386, 474, 447, 528],\n    \"BMI\": [40.50, 22.68, 28.56, 22.92, 38.39, 29.48, 23.61, 33.33, 18.85, 40.74],\n    \"DiabetesPedigreeFunction\": [0.90, 0.79, 1.85, 1.45, 0.65, 1.14, 1.04, 1.92, 1.69, 1.49],\n    \"Age\": [67, 44, 46, 45, 65, 61, 49, 35, 65, 21],\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = svm_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.124746Z","iopub.execute_input":"2025-03-01T20:57:48.125199Z","iopub.status.idle":"2025-03-01T20:57:48.140658Z","shell.execute_reply.started":"2025-03-01T20:57:48.125162Z","shell.execute_reply":"2025-03-01T20:57:48.139475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diabetes SVC con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nsvm_model = SVC(C=10, kernel=\"rbf\", gamma='scale')\nmodelo = \"Support Vector Machine\"\n\n# Le pasamos los datos de entrenamiento y testeo\nsvm_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_SVC = svm_model.predict(X_train)\ny_test_SVC = svm_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_SVC))\n\nauc = roc_auc_score(y_train, y_train_SVC)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_SVC)\nprint(f\"Cohen's Kappa: {kappa}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-01T20:57:48.141799Z","iopub.execute_input":"2025-03-01T20:57:48.142208Z","iopub.status.idle":"2025-03-01T20:57:48.221910Z","shell.execute_reply.started":"2025-03-01T20:57:48.142173Z","shell.execute_reply":"2025-03-01T20:57:48.220849Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El kernel RBF no ha mejorado sustancialmente el modelo en este caso.\nSigue existiendo un desequilibrio en la detección de la clase 1.","metadata":{}},{"cell_type":"markdown","source":"# 2. Regresión Logistica\n\nLa regresión logística es un algoritmo de aprendizaje supervisado utilizado para problemas de clasificación binaria. Su objetivo es modelar la probabilidad de que una instancia pertenezca a una de dos clases, utilizando una función logística o sigmoide, que convierte los valores predichos en un rango de 0 a 1.\n\nEl modelo de regresión logística realiza una predicción al estimar la probabilidad de que un evento ocurra. Esto se logra mediante una combinación lineal de las características de entrada, a la que se aplica una función sigmoide (también conocida como función logística). El valor de salida es una probabilidad entre 0 y 1, que luego se interpreta como la probabilidad de que una instancia pertenezca a la clase positiva (por ejemplo, la clase \"1\"). Si la probabilidad es mayor que un umbral predefinido (generalmente 0.5), el modelo predice la clase positiva, de lo contrario, predice la clase negativa (por ejemplo, la clase \"0\").","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset Regresion Logistica","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nX = phishing.drop([\"class\"],axis =1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nrl_model = LogisticRegression()\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.222967Z","iopub.execute_input":"2025-03-01T20:57:48.223298Z","iopub.status.idle":"2025-03-01T20:57:48.350621Z","shell.execute_reply.started":"2025-03-01T20:57:48.223253Z","shell.execute_reply":"2025-03-01T20:57:48.349072Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo presenta un desempeño sólido en la detección de direcciones maliciosas. Con una precisión del 93 % y un recall del 95 % para la clase de direcciones maliciosas (clase 1), demuestra una alta capacidad para identificar correctamente sitios de phishing.\n\nEl f1-score de 0.94 para la clase 1 indica un buen equilibrio entre precisión y recall, minimizando tanto los falsos positivos como los falsos negativos. Además, la métrica AUC de 0.92 sugiere una buena capacidad de discriminación del modelo.\n\nEl Cohen's Kappa de 0.85 refuerza la idea de que el modelo tiene un acuerdo significativo con la clasificación real, más allá de la coincidencia aleatoria. En general, estos resultados muestran que el modelo es confiable y efectivo para identificar direcciones potencialmente maliciosas. ","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino con Regresion Logistica","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nX = wine.drop([\"quality\"],axis =1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo\nrl_model = LogisticRegression()\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.352523Z","iopub.execute_input":"2025-03-01T20:57:48.353058Z","iopub.status.idle":"2025-03-01T20:57:48.434698Z","shell.execute_reply.started":"2025-03-01T20:57:48.353007Z","shell.execute_reply":"2025-03-01T20:57:48.431659Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de clasificación binaria para la detección de la calidad del vino muestra un rendimiento aceptable, con una precisión global del 77 %. La clase de vinos buenos (1) tiene un f1-score de 0.79, lo que indica un buen equilibrio entre precisión y recall, mientras que la clase de vinos malos (0) tiene un f1-score de 0.74, sugiriendo que es ligeramente más difícil de clasificar correctamente.\n\nEl AUC de 0.76 indica que el modelo tiene una capacidad moderada para discriminar entre vinos buenos y malos, aunque hay margen de mejora. Además, el Cohen's Kappa de 0.51 sugiere un acuerdo moderado con la clasificación real, lo que indica que el modelo supera la clasificación aleatoria, pero aún podría beneficiarse de mejoras.","metadata":{}},{"cell_type":"markdown","source":"## Diagnóstico de Cáncer de Mama con Regresion Logistica","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo\nrl_model = LogisticRegression()\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.437400Z","iopub.execute_input":"2025-03-01T20:57:48.437912Z","iopub.status.idle":"2025-03-01T20:57:48.493967Z","shell.execute_reply.started":"2025-03-01T20:57:48.437870Z","shell.execute_reply":"2025-03-01T20:57:48.492816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo para la detección de cáncer de mama muestra un desempeño excepcional, con una precisión global del 96 %. Tanto la clase de pacientes sin cáncer (0) como la de pacientes con cáncer (1) tienen f1-scores altos (0.97 y 0.95, respectivamente), lo que indica un buen equilibrio entre precisión y recall en ambas categorías.\n\nEl AUC de 0.99 sugiere que el modelo tiene una capacidad de discriminación excelente, siendo capaz de diferenciar con gran precisión entre casos positivos y negativos. Además, el Cohen’s Kappa de 0.98 indica un acuerdo casi perfecto con la clasificación real, lo que refuerza la confiabilidad del modelo.\n\nEstos resultados sugieren que el modelo es altamente preciso y efectivo para la detección del cáncer de mama. ","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con Regresion Logistica","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo\nrl_model = LogisticRegression()\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.494958Z","iopub.execute_input":"2025-03-01T20:57:48.495355Z","iopub.status.idle":"2025-03-01T20:57:48.536964Z","shell.execute_reply.started":"2025-03-01T20:57:48.495312Z","shell.execute_reply":"2025-03-01T20:57:48.535820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo para la detección de la diabetes presenta un rendimiento moderado, con una precisión global del 75 %. La clase de pacientes sin diabetes (0) tiene un f1-score de 0.81, lo que indica que el modelo identifica bien a los casos negativos. Sin embargo, la clase de pacientes con diabetes (1) tiene un f1-score de 0.66, lo que sugiere dificultades para detectar correctamente los casos positivos.\n\nEl AUC de 0.72 indica una capacidad de discriminación aceptable, aunque podría mejorarse. El Cohen’s Kappa de 0.47 sugiere un acuerdo moderado con la clasificación real, pero deja margen para optimización.","metadata":{}},{"cell_type":"markdown","source":"## Análisis Comparativo del Algoritmo en los Diferentes Datasets\n\n| **Dataset**              | **Accuracy** | **F1-Score (Clase 1)** | **AUC**  | **Cohen’s Kappa** |\n|--------------------------|-------------|------------------------|----------|-------------------|\n| **Detección de phishing** | 0.93        | 0.94                   | 0.92     | 0.85              |\n| **Calidad del vino**      | 0.77        | 0.79                   | 0.76     | 0.51              |\n| **Cáncer de mama**        | 0.96        | 0.95                   | 0.99     | 0.98              |\n| **Detección de diabetes** | 0.75        | 0.66                   | 0.72     | 0.47              |\n\n\n- El modelo funciona mejor en problemas donde los patrones son más claros, como en la detección de cáncer de mama y phishing.\n\n- La detección de calidad del vino y diabetes son problemas más desafiantes, posiblemente debido a la variabilidad de los datos y a la dificultad de encontrar límites claros entre las clases.","metadata":{}},{"cell_type":"markdown","source":"## Ajustes de Hiperparámetros\n\n1. **C (Regularización)**:\n   - Controla la fuerza de la regularización L2. Un valor más bajo de `C` implica una mayor regularización (mayor penalización por pesos grandes), mientras que un valor más alto permite más flexibilidad en el ajuste del modelo, lo que puede llevar a sobreajuste.\n\n2. **Solver (Algoritmo de optimización)**:\n   - Determina el algoritmo utilizado para minimizar la función de costo (entropía cruzada). Las opciones comunes son:\n     - `liblinear`: Buen rendimiento con conjuntos de datos pequeños o cuando se utiliza regularización L1.\n     - `newton-cg`: Apropiado para modelos con más datos.\n     - `lbfgs`: Variante del método de Newton.\n     - `saga`: Buen rendimiento para regularización L1 y L2.\n\n3. **Max_iter (Número máximo de iteraciones)**:\n   - Define el número máximo de iteraciones que el solver realizará para encontrar una solución. Si el modelo no converge en el número especificado, se detendrá.\n\n4. **Tol (Tolerancia para la convergencia)**:\n   - Establece el criterio de convergencia del algoritmo de optimización. El entrenamiento terminará si el cambio en la función de coste es menor que este valor.\n\n5. **Intercept_scaling (Escalado del término independiente)**:\n   - Solo se aplica si se usa el solver `liblinear`. Controla cómo el término independiente (intercepto) se escala con respecto a las características.\n\n6. **Fit_intercept (Incluir el término independiente)**:\n   - Si es `True`, el modelo incluirá un término independiente en la ecuación. Si es `False`, no lo incluirá (lo que significa que forzarás al modelo a pasar por el origen).\n\n7. **Class_weight (Peso de las clases)**:\n   - Puedes usar esto para ajustar el modelo a clases desbalanceadas, asignando un mayor peso a las clases minoritarias.\n\n8. **Multi_class (Clasificación multiclase)**:\n   - Aunque es más común en problemas multiclase, se puede establecer si se usa la regresión logística en un contexto multiclase. Para la clasificación binaria, generalmente se deja en su valor predeterminado (`ovr`).\n\n9. **Warm_start (Reinicio del ajuste)**:\n   - Si es `True`, el modelo conservará los resultados de la iteración anterior y continuará el entrenamiento. Si es `False`, el modelo se entrenará desde cero.\n\n10. **Penalty (Tipo de regularización)**:\n    - Define el tipo de regularización a utilizar. Las opciones comunes son:\n      - `l2`: Regularización L2 (más común en regresión logística).\n      - `l1`: Regularización L1 (puede generar un modelo más esparso).\n","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset de Regresion Logistica con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo con una combinación de hiperparámetros ajustados manualmente\nrl_model = LogisticRegression(\n    C=1,                # Regularización moderada\n    solver='liblinear', # Método de optimización 'liblinear' (bueno para problemas pequeños o medianos)\n    max_iter=200,       # Aumentamos el número de iteraciones para garantizar la convergencia\n    penalty='l2',       # Regularización L2 (más común)\n    random_state=42     # Para hacer reproducible los resultados\n)\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.538363Z","iopub.execute_input":"2025-03-01T20:57:48.538669Z","iopub.status.idle":"2025-03-01T20:57:48.686551Z","shell.execute_reply.started":"2025-03-01T20:57:48.538645Z","shell.execute_reply":"2025-03-01T20:57:48.685078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de regresión logística tiene un buen rendimiento, con una precisión y recall muy altas tanto para la clase -1 como para la clase 1. La AUC es excelente (0.92), lo que indica que el modelo es bastante bueno para distinguir entre las clases. Además, el Cohen's Kappa (0.85) sugiere una buena concordancia entre las predicciones y las etiquetas reales, lo que indica un modelo fiable.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset de Regresion Logistica con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrl_model = LogisticRegression(\n    C=0.5,              # Regularización más baja (menos penalización)\n    solver='lbfgs',     # Usamos un optimizador diferente (más eficiente para grandes datasets)\n    max_iter=300,       # Aumentamos aún más el número de iteraciones para garantizar la convergencia\n    penalty='l2',       # Regularización L2\n    random_state=42     # Para reproducibilidad\n)\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.688164Z","iopub.execute_input":"2025-03-01T20:57:48.688603Z","iopub.status.idle":"2025-03-01T20:57:48.792440Z","shell.execute_reply.started":"2025-03-01T20:57:48.688572Z","shell.execute_reply":"2025-03-01T20:57:48.791378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El rendimiento del modelo sigue siendo excelente, con una precisión y recall equilibrados para ambas clases, así como una AUC de 0.92, lo que indica que el modelo sigue siendo capaz de distinguir bien entre las clases. El Cohen's Kappa ha mejorado ligeramente, lo que indica una ligera mejora en la concordancia entre las predicciones y las etiquetas reales. En general, el modelo está funcionando muy bien.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset de Regresion Logistica con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrl_model = LogisticRegression(\n    C=10,               # Aumento la regularización (más flexible)\n    solver='saga',      # Optimización con 'saga', eficiente para grandes datasets y L1/L2\n    max_iter=300,       # Mantengo un número alto de iteraciones para asegurar la convergencia\n    penalty='elasticnet', # Usamos una regularización elástica (combinación L1 y L2)\n    l1_ratio=0.5,       # Equilibrio entre L1 y L2 (0.5 significa un balance)\n    random_state=42     # Para reproducibilidad\n)\n\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:48.793559Z","iopub.execute_input":"2025-03-01T20:57:48.793863Z","iopub.status.idle":"2025-03-01T20:57:49.929787Z","shell.execute_reply.started":"2025-03-01T20:57:48.793839Z","shell.execute_reply":"2025-03-01T20:57:49.928495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sigue mostrando un rendimiento muy sólido, con precisión y recall altos para ambas clases, lo que indica que el modelo está equilibrado y bien ajustado. La AUC de 0.92 sigue siendo excelente, lo que sugiere que el modelo tiene una excelente capacidad de discriminación entre las clases. El Cohen's Kappa se mantiene alto (0.85), lo que refleja una buena concordancia entre las predicciones y las etiquetas reales. Aunque ha habido una ligera disminución en el AUC y el Cohen's Kappa en comparación con las pruebas anteriores, los resultados siguen siendo bastante buenos.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"UsingIP\": np.random.choice([0, 1], 10),\n    \"LongURL\": np.random.choice([0, 1], 10),\n    \"ShortURL\": np.random.choice([0, 1], 10),\n    \"Symbol@\": np.random.choice([0, 1], 10),\n    \"Redirecting//\": np.random.choice([0, 1], 10),\n    \"PrefixSuffix-\": np.random.choice([0, 1], 10),\n    \"SubDomains\": np.random.choice([0, 1], 10),\n    \"HTTPS\": np.random.choice([0, 1], 10),\n    \"DomainRegLen\": np.random.randint(5, 15, 10),\n    \"Favicon\": np.random.choice([0, 1], 10),\n    \"NonStdPort\": np.random.choice([0, 1], 10),\n    \"HTTPSDomainURL\": np.random.choice([0, 1], 10),\n    \"RequestURL\": np.random.choice([0, 1], 10),\n    \"AnchorURL\": np.random.choice([0, 1], 10),\n    \"LinksInScriptTags\": np.random.choice([0, 1], 10),\n    \"ServerFormHandler\": np.random.choice([0, 1], 10),\n    \"InfoEmail\": np.random.choice([0, 1], 10),\n    \"AbnormalURL\": np.random.choice([0, 1], 10),\n    \"WebsiteForwarding\": np.random.choice([0, 1], 10),\n    \"StatusBarCust\": np.random.choice([0, 1], 10),\n    \"DisableRightClick\": np.random.choice([0, 1], 10),\n    \"UsingPopupWindow\": np.random.choice([0, 1], 10),\n    \"IframeRedirection\": np.random.choice([0, 1], 10),\n    \"AgeofDomain\": np.random.randint(1, 20, 10),\n    \"DNSRecording\": np.random.choice([0, 1], 10),\n    \"WebsiteTraffic\": np.random.randint(1000, 10000, 10),\n    \"PageRank\": np.random.randint(0, 10, 10),\n    \"GoogleIndex\": np.random.randint(0, 1000, 10),\n    \"LinksPointingToPage\": np.random.randint(0, 100, 10),\n    \"StatsReport\": np.random.choice([0, 1], 10),\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = rl_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:49.930959Z","iopub.execute_input":"2025-03-01T20:57:49.931331Z","iopub.status.idle":"2025-03-01T20:57:49.952396Z","shell.execute_reply.started":"2025-03-01T20:57:49.931267Z","shell.execute_reply":"2025-03-01T20:57:49.951055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calidad del Vino de Regresion Logistica con Hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo con algunos hiperparámetros ajustados\nrl_model = LogisticRegression(\n    C=0.5,               # Regularización más baja (modelo más flexible)\n    solver='lbfgs',      # Optimización con 'lbfgs', eficiente para grandes datasets\n    max_iter=200,        # Aumento el número de iteraciones para asegurar la convergencia\n    penalty='l2',        # Regularización L2\n    random_state=42      # Para reproducibilidad\n)\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:49.953427Z","iopub.execute_input":"2025-03-01T20:57:49.953762Z","iopub.status.idle":"2025-03-01T20:57:50.005367Z","shell.execute_reply.started":"2025-03-01T20:57:49.953733Z","shell.execute_reply":"2025-03-01T20:57:50.003788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra un rendimiento moderado, con una precisión y recall equilibrados entre las dos clases, pero con un AUC de 0.76 y un Cohen's Kappa de 0.52, lo que sugiere que, aunque el modelo realiza predicciones razonables, aún tiene espacio para mejorar en la discriminación entre clases. Para mejorar el rendimiento, se recomienda ajustar los hiperparámetros, especialmente reduciendo la regularización (C más bajo), utilizando un optimizador más adecuado como 'saga' y aplicando ElasticNet para mejorar la selección de características, lo que podría mejorar tanto la capacidad de generalización como la precisión en la clasificación.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino de Regresion Logistica con Hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.1,               # Menor regularización (más capacidad de ajuste)\n    solver='saga',       # Optimización 'saga' (más eficiente para datasets grandes)\n    max_iter=500,        # Aumento de iteraciones para mejorar la convergencia\n    penalty='elasticnet',# Usamos ElasticNet (combina L1 y L2)\n    l1_ratio=0.7,        # Predomina la regularización L1, favoreciendo la selección de características\n    random_state=42      # Para reproducibilidad\n)\n\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.006490Z","iopub.execute_input":"2025-03-01T20:57:50.006915Z","iopub.status.idle":"2025-03-01T20:57:50.047350Z","shell.execute_reply.started":"2025-03-01T20:57:50.006885Z","shell.execute_reply":"2025-03-01T20:57:50.045779Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo presenta un rendimiento razonable, con una precisión y recall algo equilibrados entre las clases, y un f1-score similar para ambas. Aunque la AUC de 0.76 y el Cohen's Kappa de 0.51 sugieren una capacidad de discriminación moderada, el modelo aún tiene margen para mejorar, especialmente en términos de su capacidad para generalizar y diferenciar entre las clases. Un modelo con una accuracy de 0.74 es prometedor, pero podría beneficiarse de un ajuste en los hiperparámetros para aumentar su precisión y reducir el sesgo.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino de Regresion Logistica con Hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.05,              # Aumento de la regularización (más fuerte, para evitar sobreajuste)\n    solver='saga',       # Usamos el optimizador 'saga' para mayor eficiencia\n    max_iter=500,        # Aumento de las iteraciones para asegurar que el modelo converge\n    penalty='elasticnet',# ElasticNet para usar tanto L1 como L2 en la regularización\n    l1_ratio=0.6,        # Ligeramente más L1 para hacer una selección de características más eficiente\n    random_state=42      # Para reproducibilidad\n)\n\n\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.048547Z","iopub.execute_input":"2025-03-01T20:57:50.048875Z","iopub.status.idle":"2025-03-01T20:57:50.087052Z","shell.execute_reply.started":"2025-03-01T20:57:50.048848Z","shell.execute_reply":"2025-03-01T20:57:50.085848Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra una mejora respecto a los resultados anteriores, con una **precisión** y **recall** más equilibrados y un **f1-score** más alto en ambas clases. La **AUC** de 0.76 sigue siendo moderada, lo que indica que el modelo tiene un buen rendimiento, pero aún puede mejorar en la discriminación de las clases. El **Cohen's Kappa** de 0.51 sugiere una concordancia moderada, lo que implica que el modelo aún podría beneficiarse de ajustes adicionales para mejorar su capacidad de predicción en el conjunto de datos.","metadata":{}},{"cell_type":"code","source":"\ndata = {'fixed acidity': ([10.35253554,  7.26347495,  6.67898833, 12.19280472, 13.38056873,\n        11.55031192, 14.06472709, 11.6747519 , 13.20290934,  9.2585812 ]),\n        'volatile acidity': ([0.12494187, 0.93639711, 0.60643566, 0.8658896 , 0.48623281,\n        0.73974801, 0.87882902, 0.48436769, 0.9797959 , 0.68827086]),\n        'citric acid': ([0.22042425, 0.02174948, 0.66092244, 0.21206596, 0.26902823,\n        0.79488973, 0.05962322, 0.33986682, 0.56810277, 0.6550574 ]),\n        'residual sugar': ([ 9.97329302, 11.46712616, 19.59321475, 15.21857218, 19.9362865 ,\n        18.29606054, 18.60545566,  2.16459   ,  0.49073062,  4.99290913]),\n        'chlorides': ([0.01276844, 0.02554124, 0.08449844, 0.09391178, 0.08946256,\n        0.01140122, 0.03637004, 0.08003057, 0.05379014, 0.08017591]),\n        'free sulfur dioxide': ([47, 19, 37, 37,  4, 10, 48,  1,  9, 43]),\n        'total sulfur dioxide': ([91, 74, 35, 70, 46, 88, 15, 23, 83, 79]),\n        'density': ([1.04725638, 1.02393862, 1.03270583, 1.04728879, 1.00306102,\n        1.01175424, 1.0054896 , 0.98394179, 0.98215251, 1.00903544]),\n        'pH': ([2.60416364, 2.74681535, 2.73456048, 3.0179527 , 3.45726089,\n        3.10749114, 2.766903  , 2.63933977, 2.95081405, 3.37045817]),\n        'sulphates': ([0.87631514, 0.51598346, 0.79518658, 0.66021614, 0.62282499,\n        0.32949315, 0.57303068, 0.32104167, 0.76850822, 0.78956107]),\n        'alcohol': ([ 8.42640967,  9.62703237, 13.70056614,  9.44443614, 11.41589419,\n        9.26896253,  9.24523951,  8.5906224 , 11.15167205, 11.59417586])}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = rl_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.088426Z","iopub.execute_input":"2025-03-01T20:57:50.088840Z","iopub.status.idle":"2025-03-01T20:57:50.105899Z","shell.execute_reply.started":"2025-03-01T20:57:50.088800Z","shell.execute_reply":"2025-03-01T20:57:50.104617Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diagnóstico de Cáncer de Mama Regresion Logistica con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.1,               # Regularización más fuerte (menor C)\n    solver='saga',       # Optimización eficiente con 'saga'\n    max_iter=500,        # Aumentamos el número de iteraciones para asegurar que el modelo converge\n    penalty='elasticnet',# Usamos ElasticNet para una combinación de L1 y L2\n    l1_ratio=0.5,        # Equilibramos la regularización L1 y L2\n    random_state=42      # Para reproducibilidad\n)\n\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.107452Z","iopub.execute_input":"2025-03-01T20:57:50.108366Z","iopub.status.idle":"2025-03-01T20:57:50.205072Z","shell.execute_reply.started":"2025-03-01T20:57:50.108261Z","shell.execute_reply":"2025-03-01T20:57:50.203238Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo presenta un rendimiento excelente, con precisiones y recalls muy altos en ambas clases, lo que se traduce en una accuracy del 96% y un AUC de 0.97, lo que indica una capacidad muy buena para discriminar entre las clases. El Cohen's Kappa de 0.96 muestra una excelente concordancia entre las predicciones del modelo y los valores reales.","metadata":{}},{"cell_type":"markdown","source":"## Diagnóstico de Cáncer de Mama Regresion Logistica con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.01,               # Aumentamos la regularización para evitar el sobreajuste\n    solver='saga',        # Usamos 'saga' para eficiencia en grandes datasets\n    max_iter=1000,        # Aumentamos las iteraciones para asegurar la convergencia\n    penalty='elasticnet', # ElasticNet para una combinación de L1 y L2\n    l1_ratio=0.3,         # Aumentamos la regularización L2, para mayor estabilidad\n    random_state=42       # Para reproducibilidad\n)\n\n\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.206462Z","iopub.execute_input":"2025-03-01T20:57:50.206910Z","iopub.status.idle":"2025-03-01T20:57:50.250076Z","shell.execute_reply.started":"2025-03-01T20:57:50.206868Z","shell.execute_reply":"2025-03-01T20:57:50.248590Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados muestran una precisión excelente para la clase 1, con un valor de 1.00, pero la recall para la clase 1 sigue siendo relativamente baja en comparación con la clase 0, lo que provoca una ligera disminución en el f1-score de esa clase. Aunque el AUC sigue siendo bastante alto (0.92), lo que indica un buen rendimiento general, la disparidad entre las clases podría mejorarse. El Cohen's Kappa de 0.87 sigue indicando una excelente concordancia, aunque la diferencia en el desempeño entre las clases es un área para ajustar.","metadata":{}},{"cell_type":"markdown","source":"## Diagnóstico de Cáncer de Mama Regresion Logistica con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"],axis =1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.05,               # Aumentar un poco la regularización para controlar el sobreajuste\n    solver='saga',        # Continuamos usando 'saga' por su eficiencia\n    max_iter=1000,        # Aumentamos las iteraciones para asegurar la convergencia\n    penalty='elasticnet', # ElasticNet para regularización L1 y L2\n    l1_ratio=0.4,         # Aumentamos la regularización L2 para mayor estabilidad\n    class_weight='balanced',  # Asignamos un peso a las clases para balancear el desajuste entre ellas\n    random_state=42       # Para reproducibilidad\n)\n\n\n\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.251769Z","iopub.execute_input":"2025-03-01T20:57:50.252210Z","iopub.status.idle":"2025-03-01T20:57:50.313914Z","shell.execute_reply.started":"2025-03-01T20:57:50.252178Z","shell.execute_reply":"2025-03-01T20:57:50.312797Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados son excelentes, con una **precisión** muy alta para ambas clases y una **recall** sólida en ambas, especialmente para la clase 0. El **f1-score** es igualmente alto, lo que indica un buen equilibrio entre precisión y recall. La **accuracy** de 96% y el **AUC** de 0.98 confirman que el modelo tiene una excelente capacidad de discriminación. El **Cohen's Kappa** de 0.96 sugiere una excelente concordancia entre las predicciones y los valores reales. En general, el modelo muestra un rendimiento robusto y bien equilibrado.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"x.radius_mean\": [14.0, 15.5, 13.2, 14.5, 15.0, 13.8, 14.2, 16.1, 15.3, 14.6],\n    \"x.texture_mean\": [19.0, 20.3, 18.5, 17.2, 21.1, 20.0, 18.8, 19.5, 20.2, 19.3],\n    \"x.perimeter_mean\": [85.0, 90.5, 80.3, 84.6, 89.7, 82.1, 86.4, 88.9, 87.5, 85.3],\n    \"x.area_mean\": [500.0, 550.2, 480.5, 510.6, 545.0, 495.0, 520.1, 530.4, 515.3, 505.2],\n    \"x.smoothness_mean\": [0.1, 0.12, 0.09, 0.11, 0.1, 0.08, 0.1, 0.13, 0.12, 0.1],\n    \"x.compactness_mean\": [0.02, 0.03, 0.025, 0.021, 0.03, 0.015, 0.02, 0.03, 0.02, 0.022],\n    \"x.concavity_mean\": [0.05, 0.07, 0.06, 0.055, 0.065, 0.045, 0.05, 0.06, 0.055, 0.05],\n    \"x.concave_pts_mean\": [0.03, 0.035, 0.02, 0.04, 0.03, 0.025, 0.03, 0.03, 0.025, 0.03],\n    \"x.symmetry_mean\": [0.18, 0.2, 0.17, 0.19, 0.18, 0.17, 0.18, 0.21, 0.19, 0.18],\n    \"x.fractal_dim_mean\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.046, 0.047, 0.05, 0.048, 0.05],\n    \"x.radius_se\": [0.03, 0.04, 0.02, 0.03, 0.04, 0.02, 0.03, 0.02, 0.03, 0.04],\n    \"x.texture_se\": [0.04, 0.05, 0.03, 0.04, 0.05, 0.03, 0.04, 0.03, 0.05, 0.04],\n    \"x.perimeter_se\": [0.12, 0.13, 0.1, 0.11, 0.12, 0.09, 0.11, 0.12, 0.1, 0.11],\n    \"x.area_se\": [30.0, 35.2, 28.5, 32.1, 33.5, 29.3, 30.2, 31.6, 32.8, 30.5],\n    \"x.smoothness_se\": [0.002, 0.0025, 0.0018, 0.0022, 0.002, 0.0019, 0.0021, 0.0023, 0.0021, 0.002],\n    \"x.compactness_se\": [0.001, 0.0015, 0.0012, 0.0011, 0.0013, 0.001, 0.0011, 0.0013, 0.0012, 0.0011],\n    \"x.concavity_se\": [0.0025, 0.003, 0.0027, 0.0026, 0.0031, 0.0023, 0.0025, 0.0028, 0.0026, 0.0027],\n    \"x.concave_pts_se\": [0.001, 0.0012, 0.0009, 0.001, 0.0011, 0.0008, 0.001, 0.0011, 0.001, 0.0009],\n    \"x.symmetry_se\": [0.008, 0.01, 0.009, 0.0085, 0.009, 0.008, 0.0085, 0.009, 0.0087, 0.008],\n    \"x.fractal_dim_se\": [0.003, 0.0035, 0.0028, 0.0032, 0.0031, 0.0029, 0.003, 0.0031, 0.0032, 0.003],\n    \"x.radius_worst\": [17.0, 18.5, 16.5, 17.8, 18.3, 16.9, 17.4, 18.7, 17.9, 17.2],\n    \"x.texture_worst\": [22.0, 23.3, 21.8, 22.5, 23.1, 22.3, 21.9, 23.0, 22.8, 22.1],\n    \"x.perimeter_worst\": [110.0, 120.3, 115.2, 113.5, 119.4, 114.6, 117.5, 120.0, 118.2, 115.8],\n    \"x.area_worst\": [800.0, 850.5, 780.3, 800.2, 830.0, 790.1, 810.5, 830.4, 820.2, 800.5],\n    \"x.smoothness_worst\": [0.13, 0.14, 0.12, 0.13, 0.14, 0.13, 0.13, 0.14, 0.13, 0.12],\n    \"x.compactness_worst\": [0.03, 0.035, 0.031, 0.028, 0.032, 0.03, 0.029, 0.031, 0.03, 0.029],\n    \"x.concavity_worst\": [0.07, 0.08, 0.075, 0.071, 0.078, 0.073, 0.074, 0.079, 0.076, 0.075],\n    \"x.concave_pts_worst\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.04, 0.045, 0.06, 0.048, 0.05],\n    \"x.symmetry_worst\": [0.22, 0.23, 0.21, 0.22, 0.23, 0.22, 0.21, 0.22, 0.22, 0.21],\n    \"x.fractal_dim_worst\": [0.05, 0.06, 0.048, 0.05, 0.055, 0.051, 0.052, 0.05, 0.053, 0.054]\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = rl_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.315093Z","iopub.execute_input":"2025-03-01T20:57:50.315488Z","iopub.status.idle":"2025-03-01T20:57:50.339664Z","shell.execute_reply.started":"2025-03-01T20:57:50.315444Z","shell.execute_reply":"2025-03-01T20:57:50.338548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diabetes con Regresion Logistica con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.1,                # Menos regularización para permitir mayor ajuste al modelo\n    solver='liblinear',   # Usamos el optimizador 'liblinear', adecuado para pequeños conjuntos de datos\n    max_iter=1000,        # Aumentamos las iteraciones para asegurar que el modelo converja\n    penalty='l2',         # Regularización L2 estándar\n    class_weight='balanced',  # Ajustamos los pesos de las clases para manejar posibles desbalanceos en los datos\n    random_state=42       # Para reproducibilidad\n)\n\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.340894Z","iopub.execute_input":"2025-03-01T20:57:50.341382Z","iopub.status.idle":"2025-03-01T20:57:50.392334Z","shell.execute_reply.started":"2025-03-01T20:57:50.341354Z","shell.execute_reply":"2025-03-01T20:57:50.391112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados del modelo muestran una precision relativamente buena para la clase 0, pero una recall bastante baja para la misma clase, lo que indica que el modelo podría estar clasificando mal varios ejemplos de la clase 0. Por otro lado, la recall para la clase 1 es mejor, pero la precision es baja, lo que sugiere que el modelo tiene un mayor número de falsos positivos en esta clase. El f1-score para la clase 1 es más bajo, lo que refleja el desbalance entre precisión y recall. La accuracy es del 69%, pero el AUC de 0.76 sugiere que el modelo tiene una capacidad razonable para discriminar entre las clases. El Cohen's Kappa de 0.49 indica una concordancia moderada entre las predicciones y los valores reales.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con Regresion Logistica con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=0.5,               # Regularización más suave (menos penalización para los pesos)\n    solver='liblinear',  # Utilizamos 'liblinear', eficiente para problemas más pequeños\n    max_iter=1000,       # Aumentamos las iteraciones para asegurar la convergencia\n    penalty='l2',        # Regularización L2, que es más común y efectiva en muchos casos\n    class_weight='balanced',  # Ajustamos los pesos de las clases para manejar el desbalance entre clases\n    random_state=42      # Para reproducibilidad\n)\n\n\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.393347Z","iopub.execute_input":"2025-03-01T20:57:50.393650Z","iopub.status.idle":"2025-03-01T20:57:50.431624Z","shell.execute_reply.started":"2025-03-01T20:57:50.393625Z","shell.execute_reply":"2025-03-01T20:57:50.429839Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sigue mostrando un bajo rendimiento en precisión para la clase 1, aunque la recall de la clase 1 ha mejorado, lo que indica que está identificando más correctamente los casos positivos, pero aún sigue teniendo un alto número de falsos positivos. La precision para la clase 0 sigue siendo buena, pero la recall sigue siendo baja, lo que sugiere que el modelo podría estar perdiendo ejemplos importantes de la clase 0. El f1-score sigue siendo bajo en la clase 1 debido a la baja precisión, mientras que la clase 0 tiene un mejor desempeño. La AUC de 0.76 sugiere que el modelo tiene una capacidad razonable para diferenciar entre las clases, pero todavía hay espacio para mejorar. El Cohen's Kappa indica una concordancia moderada entre las predicciones y las etiquetas reales.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con Regresion Logistica con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"],axis =1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nrl_model = LogisticRegression(\n    C=1.0,              # Regularización estándar (ajustable según el modelo)\n    solver='newton-cg', # Usamos el optimizador 'newton-cg'\n    max_iter=1000,      # Aumento del número de iteraciones para asegurar la convergencia\n    penalty='l2',       # Penalización L2 para la regularización\n    class_weight='balanced', # Ajuste de pesos para clases desbalanceadas\n    random_state=42     # Para reproducibilidad\n)\n\n\nmodelo = \"Regresion Logistica\"\n\n# Le pasamos los datos de entrenamiento y testeo\nrl_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_RL = rl_model.predict(X_train)\ny_test_RL = rl_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_RL))\n\nauc = roc_auc_score(y_train, y_train_RL)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RL)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.432823Z","iopub.execute_input":"2025-03-01T20:57:50.433148Z","iopub.status.idle":"2025-03-01T20:57:50.482510Z","shell.execute_reply.started":"2025-03-01T20:57:50.433124Z","shell.execute_reply":"2025-03-01T20:57:50.481389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra una precisión general moderada, con un rendimiento algo mejor en la clase 0 (no tiene la enfermedad) que en la clase 1 (sí tiene la enfermedad). El modelo tiene una precisión del 81% para la clase 0, pero solo del 56% para la clase 1. Sin embargo, el recall para la clase 1 es del 71%, lo que indica que es relativamente efectivo al identificar correctamente a los pacientes con la enfermedad. El modelo también tiene una AUC de 0.76, lo que refleja una capacidad razonable para discriminar entre las clases, pero podría mejorarse. El valor de Cohen's Kappa sugiere una moderada concordancia entre las predicciones y los valores reales.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"Pregnancies\": [6, 14, 10, 7, 6, 10, 10, 3, 7, 2],\n    \"Glucose\": [122, 71, 157, 107, 199, 90, 127, 91, 158, 118],\n    \"BloodPressure\": [108, 91, 109, 64, 111, 111, 96, 111, 100, 104],\n    \"SkinThickness\": [12, 46, 16, 30, 18, 48, 27, 13, 34, 23],\n    \"Insulin\": [261, 796, 365, 584, 359, 111, 386, 474, 447, 528],\n    \"BMI\": [40.50, 22.68, 28.56, 22.92, 38.39, 29.48, 23.61, 33.33, 18.85, 40.74],\n    \"DiabetesPedigreeFunction\": [0.90, 0.79, 1.85, 1.45, 0.65, 1.14, 1.04, 1.92, 1.69, 1.49],\n    \"Age\": [67, 44, 46, 45, 65, 61, 49, 35, 65, 21],\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = rl_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.483656Z","iopub.execute_input":"2025-03-01T20:57:50.484111Z","iopub.status.idle":"2025-03-01T20:57:50.502207Z","shell.execute_reply.started":"2025-03-01T20:57:50.484030Z","shell.execute_reply":"2025-03-01T20:57:50.501154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Árboles de Decisión\n\nLos árboles de decisión son un algoritmo de aprendizaje supervisado utilizado tanto para tareas de clasificación como de regresión. Este modelo se basa en la construcción de un árbol binario en el cual cada nodo interno representa una prueba sobre una característica, cada rama representa el resultado de la prueba, y cada hoja representa una predicción o una clase final. La estructura resultante es fácil de interpretar, lo que hace a los árboles de decisión populares en situaciones donde la interpretabilidad es importante.","metadata":{}},{"cell_type":"markdown","source":"# Phising dataset Arboles de Decision","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Definir las variables\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Establecer la semilla para la reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalizar los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión sin hiperparámetros\ndt_model = DecisionTreeClassifier(random_state=42)\n\n# Entrenar el modelo con los datos de entrenamiento\ndt_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_dt = dt_model.predict(X_train)\ny_test_dt = dt_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_dt))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_dt)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_dt)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.503408Z","iopub.execute_input":"2025-03-01T20:57:50.503800Z","iopub.status.idle":"2025-03-01T20:57:50.835090Z","shell.execute_reply.started":"2025-03-01T20:57:50.503764Z","shell.execute_reply":"2025-03-01T20:57:50.833799Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados muestran que el modelo de Árbol de Decisión es muy eficaz para clasificar las instancias del conjunto de datos, con un rendimiento impresionante en todas las métricas clave. Este modelo está haciendo un excelente trabajo en identificar correctamente ambas clases, y su alta puntuación en AUC y Cohen's Kappa refuerzan su capacidad para generalizar bien sobre los datos.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino con Arboles de Decision","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión sin hiperparámetros\ntree_model = DecisionTreeClassifier(random_state=42)\nmodelo = \"Árbol de Decisión\"\n\n# Le pasamos los datos de entrenamiento y testeo\ntree_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_train, y_train_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.836484Z","iopub.execute_input":"2025-03-01T20:57:50.836891Z","iopub.status.idle":"2025-03-01T20:57:50.876035Z","shell.execute_reply.started":"2025-03-01T20:57:50.836851Z","shell.execute_reply":"2025-03-01T20:57:50.874888Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión ha mostrado un rendimiento decente, con alta precisión y recall en las predicciones, especialmente en las clases más frecuentes, lo que se refleja en un buen F1-Score. El AUC alto sugiere una excelente capacidad de discriminación entre clases, y el valor positivo de Cohen's Kappa indica una buena consistencia en las predicciones.","metadata":{}},{"cell_type":"markdown","source":"## Diagnostico del cancer de mama con arboles de decision","metadata":{}},{"cell_type":"code","source":"X = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión sin hiperparámetros\ntree_model = DecisionTreeClassifier(random_state=42)\nmodelo = \"Árbol de Decisión\"\n\n# Le pasamos los datos de entrenamiento y testeo\ntree_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\n\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_train, y_train_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.877322Z","iopub.execute_input":"2025-03-01T20:57:50.877745Z","iopub.status.idle":"2025-03-01T20:57:50.918099Z","shell.execute_reply.started":"2025-03-01T20:57:50.877708Z","shell.execute_reply":"2025-03-01T20:57:50.916921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión sin hiperparámetros ha mostrado un rendimiento sólido en el conjunto de datos de clasificación binaria. La precisión y el recall son bastante equilibrados, con valores cercanos al 91-94%, lo que indica que el modelo tiene una buena capacidad para predecir correctamente ambas clases. Además, el AUC de 1.0 y el Cohen's Kappa de 1.0 sugieren que el modelo ha logrado una clasificación perfecta en los datos de prueba, sin errores de clasificación. Estos resultados indican que el modelo tiene una alta capacidad de generalización y es altamente preciso.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con Arboles de Decision","metadata":{}},{"cell_type":"code","source":"# Preparación de los datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión sin hiperparámetros\ntree_model = DecisionTreeClassifier(random_state=42)\nmodelo = \"Árbol de Decisión\"\n\n# Entrenamiento del modelo\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_train, y_train_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.919443Z","iopub.execute_input":"2025-03-01T20:57:50.919821Z","iopub.status.idle":"2025-03-01T20:57:50.958772Z","shell.execute_reply.started":"2025-03-01T20:57:50.919794Z","shell.execute_reply":"2025-03-01T20:57:50.957746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión ha mostrado un rendimiento bastante bueno en términos generales, con una precisión del 75% en el conjunto de prueba. Sin embargo, las métricas como la **precision** y **recall** para las clases 0 y 1 muestran una diferencia importante. Para la clase 0, el modelo tiene una **precision** de 0.83 y un **recall** de 0.76, lo que indica que tiene un buen rendimiento al predecir la clase 0, aunque podría mejorar su capacidad de identificar todos los casos de esta clase. Para la clase 1, aunque el **recall** es relativamente bueno (0.73), la **precision** es más baja (0.62), lo que sugiere que el modelo predice la clase 1 con menos fiabilidad.\n\nA pesar de estas diferencias, la **AUC** perfecta de 1.0 indica que el modelo tiene una capacidad excelente para distinguir entre las clases en términos de probabilidad, y el **Cohen's Kappa** de 1.0 sugiere que el modelo está realizando predicciones que son prácticamente perfectas en comparación con una clasificación aleatoria.\n\nEn resumen, el modelo presenta un buen desempeño global, aunque puede mejorar en términos de precisión en la clase 1. Las métricas de AUC y Kappa son extremadamente altas, lo que indica que el modelo se desempeña muy bien en tareas de clasificación binaria, a pesar de las diferencias en el rendimiento entre las clases.","metadata":{}},{"cell_type":"markdown","source":"### Tabla Comparativa de Modelos\n\n| Modelo                         | Precisión Clase 0 | Precisión Clase 1 | Recall Clase 0 | Recall Clase 1 | F1-Score Clase 0 | F1-Score Clase 1 | Accuracy | AUC  | Cohen's Kappa |\n|--------------------------------|-------------------|-------------------|----------------|----------------|------------------|------------------|----------|------|---------------|\n| **Árbol de Decisión (Wine)**   | 0.94              | 0.91              | 0.94           | 0.91           | 0.94             | 0.91             | 0.93     | 1.00 | 1.00          |\n| **Árbol de Decisión (Cancer)** | 0.94              | 0.91              | 0.94           | 0.91           | 0.94             | 0.91             | 0.93     | 1.00 | 1.00          |\n| **Árbol de Decisión (Diabetes)** | 0.83              | 0.62              | 0.76           | 0.73           | 0.79             | 0.67             | 0.75     | 1.00 | 1.00          |\n| **Árbol de Decisión (Phishing)** | 0.95              | 0.97              | 0.96           | 0.96           | 0.96             | 0.96             | 0.96     | 0.96 | 0.92          |\n\n\nConclusión Final:\n\nELos árboles de decisión sin hiperparámetros han demostrado ser muy efectivos para clasificar correctamente las clases en la mayoría de los casos, especialmente en datasets con clases más equilibradas como wine y cancer. Sin embargo, es posible que haya cierto desequilibrio en datasets como diabetes, donde un mayor ajuste de parámetros podría ser necesario.","metadata":{}},{"cell_type":"markdown","source":"## Ajustes de Hiperparametros\n\n1. **`max_depth`**: \n   - Controla la **profundidad máxima** del árbol. Limitar la profundidad ayuda a evitar el **sobreajuste** (overfitting), ya que se limita la cantidad de divisiones que puede realizar el árbol.\n   \n2. **`min_samples_split`**:\n   - Define el **número mínimo de muestras** necesarias para dividir un nodo. Un valor más alto evita divisiones demasiado específicas, reduciendo el riesgo de sobreajuste.\n   \n3. **`min_samples_leaf`**:\n   - Establece el **número mínimo de muestras** que debe tener una hoja (nodo terminal). Al igual que el parámetro anterior, este valor ayuda a controlar el sobreajuste, asegurando que las hojas no contengan pocos datos.\n   \n4. **`max_features`**:\n   - Indica el **número máximo de características** que se usarán para dividir cada nodo. Esto puede ayudar a reducir la **varianza** y mejorar la generalización del modelo.\n   \n5. **`criterion`**:\n   - Es la función de **evaluación** que se usa para medir la calidad de una división. Los valores comunes son:\n     - `'gini'`: Gini impurity (impureza de Gini).\n     - `'entropy'`: Entropía (basada en la teoría de la información).\n   \n6. **`splitter`**:\n   - Especifica el **método de división** que se utiliza en cada nodo. Los valores comunes son:\n     - `'best'`: Selecciona la mejor división posible.\n     - `'random'`: Selecciona una división aleatoria.\n   \n7. **`max_leaf_nodes`**:\n   - Establece el número máximo de **hojas** (nodos terminales) que el árbol puede tener. Limitar las hojas ayuda a evitar el sobreajuste, ya que reduce la complejidad del modelo.\n   \n8. **`min_impurity_decrease`**:\n   - Es el **mínimo de disminución de impureza** requerido para dividir un nodo. Si la reducción de impureza es menor que este valor, el nodo no se dividirá.\n   \n9. **`class_weight`**:\n   - Permite ajustar el **peso** de las clases. Puede ser útil cuando las clases están **desbalanceadas**, ya que ajusta la importancia relativa de cada clase en el entrenamiento.\n\n10. **`max_samples`**:\n    - Especifica el número máximo de muestras que se utilizarán para entrenar el modelo si se usa el método de **muestra aleatoria** (bootstrap). Este parámetro se utiliza principalmente en técnicas de **bagging** como los **Random Forest**.\n","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset de Arboles de decision con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"# Definir las variables\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Establecer la semilla para la reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalizar los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión con hiperparámetros\ndt_model = DecisionTreeClassifier(\n    criterion='entropy',       # Usamos la entropía como criterio de división\n    max_depth=10,              # Limitar la profundidad máxima del árbol para evitar sobreajuste\n    min_samples_split=20,      # Número mínimo de muestras para dividir un nodo\n    min_samples_leaf=10,       # Número mínimo de muestras en cada hoja\n    max_features='sqrt',      # Usar un subconjunto aleatorio de características para cada división\n    random_state=42           # Establecer la semilla para la reproducibilidad\n)\n\n# Entrenar el modelo con los datos de entrenamiento\ndt_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_dt = dt_model.predict(X_train)\ny_test_dt = dt_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_dt))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_dt)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_dt)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:50.967673Z","iopub.execute_input":"2025-03-01T20:57:50.968018Z","iopub.status.idle":"2025-03-01T20:57:51.022847Z","shell.execute_reply.started":"2025-03-01T20:57:50.967994Z","shell.execute_reply":"2025-03-01T20:57:51.021571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión con los hiperparámetros actuales tiene un rendimiento aceptable, con una precisión y F1-score bastante equilibrados entre las clases, logrando una alta tasa de predicción correcta. La AUC de 0.92 y el Cohen's Kappa de 0.85 indican una buena concordancia entre las predicciones y las etiquetas reales.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset de Arboles de decision con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"# Definir las variables\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Establecer la semilla para la reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalizar los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndt_model = DecisionTreeClassifier(\n    criterion='gini', \n    max_depth=15, \n    min_samples_split=10, \n    min_samples_leaf=5, \n    max_features='log2', \n    random_state=42\n)\n\n\n# Entrenar el modelo con los datos de entrenamiento\ndt_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_dt = dt_model.predict(X_train)\ny_test_dt = dt_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_dt))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_dt)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_dt)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.025646Z","iopub.execute_input":"2025-03-01T20:57:51.025981Z","iopub.status.idle":"2025-03-01T20:57:51.084540Z","shell.execute_reply.started":"2025-03-01T20:57:51.025957Z","shell.execute_reply":"2025-03-01T20:57:51.083387Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión con los hiperparámetros actuales muestra un buen desempeño, logrando una precisión del 92% tanto en los datos de prueba como en los de entrenamiento. La métrica de AUC de 0.92 y un Cohen's Kappa de 0.84 indican que el modelo tiene un rendimiento sólido en términos de clasificación, con un buen equilibrio entre las clases.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset de Arboles de decision con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"# Definir las variables\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Establecer la semilla para la reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalizar los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndt_model = DecisionTreeClassifier(\n    criterion='entropy', \n    max_depth=10, \n    min_samples_split=20, \n    min_samples_leaf=8, \n    max_features='sqrt', \n    random_state=42\n)\n\n# Entrenar el modelo con los datos de entrenamiento\ndt_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_dt = dt_model.predict(X_train)\ny_test_dt = dt_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_dt))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_dt)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_dt)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.085577Z","iopub.execute_input":"2025-03-01T20:57:51.085882Z","iopub.status.idle":"2025-03-01T20:57:51.138470Z","shell.execute_reply.started":"2025-03-01T20:57:51.085858Z","shell.execute_reply":"2025-03-01T20:57:51.136894Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión con la configuración actual sigue mostrando un buen rendimiento, con una precisión general del 92% y un buen equilibrio entre las clases, especialmente con un recall alto para la clase positiva. El AUC de 0.92 y el Cohen's Kappa de 0.84 indican una clasificación robusta, aunque la diferencia en el recall entre las clases sugiere que el modelo podría mejorar su capacidad para identificar ejemplos de la clase negativa.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"UsingIP\": np.random.choice([0, 1], 10),\n    \"LongURL\": np.random.choice([0, 1], 10),\n    \"ShortURL\": np.random.choice([0, 1], 10),\n    \"Symbol@\": np.random.choice([0, 1], 10),\n    \"Redirecting//\": np.random.choice([0, 1], 10),\n    \"PrefixSuffix-\": np.random.choice([0, 1], 10),\n    \"SubDomains\": np.random.choice([0, 1], 10),\n    \"HTTPS\": np.random.choice([0, 1], 10),\n    \"DomainRegLen\": np.random.randint(5, 15, 10),\n    \"Favicon\": np.random.choice([0, 1], 10),\n    \"NonStdPort\": np.random.choice([0, 1], 10),\n    \"HTTPSDomainURL\": np.random.choice([0, 1], 10),\n    \"RequestURL\": np.random.choice([0, 1], 10),\n    \"AnchorURL\": np.random.choice([0, 1], 10),\n    \"LinksInScriptTags\": np.random.choice([0, 1], 10),\n    \"ServerFormHandler\": np.random.choice([0, 1], 10),\n    \"InfoEmail\": np.random.choice([0, 1], 10),\n    \"AbnormalURL\": np.random.choice([0, 1], 10),\n    \"WebsiteForwarding\": np.random.choice([0, 1], 10),\n    \"StatusBarCust\": np.random.choice([0, 1], 10),\n    \"DisableRightClick\": np.random.choice([0, 1], 10),\n    \"UsingPopupWindow\": np.random.choice([0, 1], 10),\n    \"IframeRedirection\": np.random.choice([0, 1], 10),\n    \"AgeofDomain\": np.random.randint(1, 20, 10),\n    \"DNSRecording\": np.random.choice([0, 1], 10),\n    \"WebsiteTraffic\": np.random.randint(1000, 10000, 10),\n    \"PageRank\": np.random.randint(0, 10, 10),\n    \"GoogleIndex\": np.random.randint(0, 1000, 10),\n    \"LinksPointingToPage\": np.random.randint(0, 100, 10),\n    \"StatsReport\": np.random.choice([0, 1], 10),\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = dt_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.139664Z","iopub.execute_input":"2025-03-01T20:57:51.139966Z","iopub.status.idle":"2025-03-01T20:57:51.160771Z","shell.execute_reply.started":"2025-03-01T20:57:51.139942Z","shell.execute_reply":"2025-03-01T20:57:51.159677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calidad del Vino con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión con algunos hiperparámetros adicionales\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='gini',              # Selección del criterio de división (Gini o Entropía)\n    max_depth=10,                  # Profundidad máxima del árbol\n    min_samples_split=20,          # Número mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=5,            # Número mínimo de muestras necesarias para ser una hoja\n    max_features='sqrt'            # Número máximo de características a considerar en cada división\n)\n\n# Le pasamos los datos de entrenamiento y testeo\ntree_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_test, y_test_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_test, y_test_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.161870Z","iopub.execute_input":"2025-03-01T20:57:51.162246Z","iopub.status.idle":"2025-03-01T20:57:51.209904Z","shell.execute_reply.started":"2025-03-01T20:57:51.162216Z","shell.execute_reply":"2025-03-01T20:57:51.208669Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión con los hiperparámetros actuales muestra un rendimiento moderado, con una precisión y recall cercanas a 0.70, lo que indica una capacidad razonable para identificar ambas clases, pero aún con margen de mejora. El valor de AUC es de 0.69, lo cual es moderadamente bueno, pero hay espacio para mejorar la capacidad del modelo para distinguir entre las clases. Además, el Cohen's Kappa de 0.39 indica una mejora en comparación con el azar, pero el modelo todavía tiene una cantidad considerable de desacuerdo con las predicciones reales. Es recomendable seguir ajustando los hiperparámetros para mejorar su desempeño.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',           # Cambiar el criterio a 'entropy' para usar la información mutua\n    max_depth=15,                  # Aumentar la profundidad máxima a 15 para capturar más relaciones complejas\n    min_samples_split=10,          # Reducir el número mínimo de muestras para dividir un nodo\n    min_samples_leaf=10,           # Aumentar el mínimo de muestras por hoja para evitar sobreajuste\n    max_features='log2',           # Probar con 'log2' para usar una cantidad logarítmica de características por división\n    class_weight='balanced'        # Ajustar el peso de las clases para manejar el desbalance de clases\n)\n\n\n# Le pasamos los datos de entrenamiento y testeo\ntree_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_test, y_test_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_test, y_test_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.211024Z","iopub.execute_input":"2025-03-01T20:57:51.211353Z","iopub.status.idle":"2025-03-01T20:57:51.248499Z","shell.execute_reply.started":"2025-03-01T20:57:51.211327Z","shell.execute_reply":"2025-03-01T20:57:51.247380Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión con los parámetros actuales muestra una mejora con respecto a la evaluación anterior. La precisión general es razonable (0.73), y tanto la precisión como el recall para la clase positiva (1) están bastante equilibrados. El AUC de 0.73 refleja una capacidad moderada para discriminar entre las clases, lo que es un indicio de que el modelo tiene un desempeño decente pero aún podría mejorar, especialmente en la clasificación de la clase 0. El Cohen's Kappa de 0.45 sugiere que el modelo está logrando una mejor concordancia que el azar, aunque aún hay margen para una mejora significativa.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',           # Usar 'entropy' en lugar de 'gini' para mejorar la selección de características\n    max_depth=20,                  # Aumentar la profundidad máxima para permitir una mayor complejidad\n    min_samples_split=5,           # Reducir el número mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=5,            # Reducir el número de muestras mínimas por hoja para mejorar la capacidad de predicción\n    max_features='sqrt',           # Utilizar la raíz cuadrada del número de características para mejorar la diversidad en las divisiones\n    class_weight='balanced'        # Ajustar el peso de las clases para manejar el desbalance entre las clases\n)\n\n\n\n# Le pasamos los datos de entrenamiento y testeo\ntree_model.fit(X_train, y_train)\n\n# Realizamos las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Vamos a evaluar el rendimiento de nuestro modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_test, y_test_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_test, y_test_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.249591Z","iopub.execute_input":"2025-03-01T20:57:51.249861Z","iopub.status.idle":"2025-03-01T20:57:51.285962Z","shell.execute_reply.started":"2025-03-01T20:57:51.249839Z","shell.execute_reply":"2025-03-01T20:57:51.284682Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Árbol de Decisión con los nuevos hiperparámetros muestra una mejora en la clasificación, especialmente en la clase positiva. La precisión y el recall para la clase 1 (calidad alta) se mantienen elevados, y el AUC de 0.73 indica una capacidad moderada de discriminación. El valor de Cohen's Kappa de 0.45 sugiere una mejor concordancia que el azar, pero sigue existiendo margen de mejora. En general, aunque el modelo es aceptable, hay oportunidades para ajustar aún más los hiperparámetros o probar otros modelos para mejorar el rendimiento, particularmente en el manejo de clases desbalanceadas y la mejora de la capacidad predictiva para las clases más raras.","metadata":{}},{"cell_type":"code","source":"data = {'fixed acidity': ([10.35253554,  7.26347495,  6.67898833, 12.19280472, 13.38056873,\n        11.55031192, 14.06472709, 11.6747519 , 13.20290934,  9.2585812 ]),\n        'volatile acidity': ([0.12494187, 0.93639711, 0.60643566, 0.8658896 , 0.48623281,\n        0.73974801, 0.87882902, 0.48436769, 0.9797959 , 0.68827086]),\n        'citric acid': ([0.22042425, 0.02174948, 0.66092244, 0.21206596, 0.26902823,\n        0.79488973, 0.05962322, 0.33986682, 0.56810277, 0.6550574 ]),\n        'residual sugar': ([ 9.97329302, 11.46712616, 19.59321475, 15.21857218, 19.9362865 ,\n        18.29606054, 18.60545566,  2.16459   ,  0.49073062,  4.99290913]),\n        'chlorides': ([0.01276844, 0.02554124, 0.08449844, 0.09391178, 0.08946256,\n        0.01140122, 0.03637004, 0.08003057, 0.05379014, 0.08017591]),\n        'free sulfur dioxide': ([47, 19, 37, 37,  4, 10, 48,  1,  9, 43]),\n        'total sulfur dioxide': ([91, 74, 35, 70, 46, 88, 15, 23, 83, 79]),\n        'density': ([1.04725638, 1.02393862, 1.03270583, 1.04728879, 1.00306102,\n        1.01175424, 1.0054896 , 0.98394179, 0.98215251, 1.00903544]),\n        'pH': ([2.60416364, 2.74681535, 2.73456048, 3.0179527 , 3.45726089,\n        3.10749114, 2.766903  , 2.63933977, 2.95081405, 3.37045817]),\n        'sulphates': ([0.87631514, 0.51598346, 0.79518658, 0.66021614, 0.62282499,\n        0.32949315, 0.57303068, 0.32104167, 0.76850822, 0.78956107]),\n        'alcohol': ([ 8.42640967,  9.62703237, 13.70056614,  9.44443614, 11.41589419,\n        9.26896253,  9.24523951,  8.5906224 , 11.15167205, 11.59417586])}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = tree_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.286995Z","iopub.execute_input":"2025-03-01T20:57:51.287317Z","iopub.status.idle":"2025-03-01T20:57:51.304418Z","shell.execute_reply.started":"2025-03-01T20:57:51.287264Z","shell.execute_reply":"2025-03-01T20:57:51.303075Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diagnostico del cancer de mama con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"# Definir las variables\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión con hiperparámetros\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',           # Usar 'entropy' para mejorar la selección de características\n    max_depth=10,                  # Limitar la profundidad para evitar el sobreajuste\n    min_samples_split=4,           # Reducir el número mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=4,            # Reducir el número mínimo de muestras por hoja\n    max_features='sqrt',           # Considerar solo la raíz cuadrada del número de características\n    class_weight='balanced'        # Ajustar el peso de las clases para manejar clases desbalanceadas\n)\n\n# Entrenar el modelo con los datos de entrenamiento\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_tree)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.305482Z","iopub.execute_input":"2025-03-01T20:57:51.305871Z","iopub.status.idle":"2025-03-01T20:57:51.351046Z","shell.execute_reply.started":"2025-03-01T20:57:51.305834Z","shell.execute_reply":"2025-03-01T20:57:51.349884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra un excelente rendimiento con una precisión, recall y f1-score muy altos, especialmente en la clase 0. La precisión y recall para la clase 1 también son buenas, aunque ligeramente inferiores. La exactitud global es del 95%, lo cual es impresionante. Además, la AUC de 0.94 sugiere que el modelo tiene una capacidad de discriminación bastante buena entre las clases. Cohen's Kappa de 0.89 indica una fuerte concordancia entre las predicciones y las etiquetas reales, lo que es otra señal de la efectividad del modelo.\n\nSin embargo, hay una ligera desventaja en el recall de la clase 1 (0.91), lo que podría implicar que el modelo está clasificando algunas muestras de la clase 1 incorrectamente como clase 0. Es posible que mejorando el ajuste del modelo, se pueda aumentar aún más la capacidad de detección de la clase 1.","metadata":{}},{"cell_type":"markdown","source":"## Diagnostico del cancer de mama con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"# Definir las variables\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',           # Usar 'entropy' para mejorar la selección de características\n    max_depth=15,                  # Limitar la profundidad para evitar el sobreajuste (ajustado a 15)\n    min_samples_split=4,           # Reducir el número mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=3,            # Reducir aún más el número de muestras por hoja\n    max_features='log2',           # Probar el logaritmo de características para mejorar la diversidad\n    class_weight='balanced',       # Ajustar el peso de las clases para manejar el desbalance de clases\n    splitter='best'                # Cambiar el tipo de divisores para permitir la mejor división\n)\n\n\n# Entrenar el modelo con los datos de entrenamiento\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_tree)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.352152Z","iopub.execute_input":"2025-03-01T20:57:51.352479Z","iopub.status.idle":"2025-03-01T20:57:51.387461Z","shell.execute_reply.started":"2025-03-01T20:57:51.352445Z","shell.execute_reply":"2025-03-01T20:57:51.386389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sigue demostrando un excelente rendimiento con una precisión, recall y f1-score balanceados entre las dos clases, y un accuracy del 93%. Aunque la clase 0 tiene ligeramente mejor rendimiento que la clase 1, ambas clases tienen buenos valores de recall (0.94 y 0.91, respectivamente), lo que sugiere que el modelo tiene un buen desempeño en la identificación de ambas clases. La AUC de 0.93 muestra que el modelo tiene una excelente capacidad para diferenciar entre las clases, y Cohen's Kappa de 0.85 indica una alta concordancia entre las predicciones y las etiquetas reales, lo que es positivo.","metadata":{}},{"cell_type":"markdown","source":"## Diagnostico del cancer de mama con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"# Definir las variables\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalización de los datos\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',           # Continuamos utilizando 'entropy' para mejorar la selección de características\n    max_depth=12,                  # Reducir la profundidad para evitar sobreajuste\n    min_samples_split=5,           # Reducir aún más el número de muestras necesarias para dividir un nodo\n    min_samples_leaf=2,            # Reducir el número de muestras por hoja para mejorar la capacidad de predicción\n    max_features='sqrt',           # Utilizar la raíz cuadrada del número de características para mayor diversidad\n    class_weight='balanced', # Probar 'balanced_subsample' para ajustar pesos en subconjuntos de muestra\n    splitter='best'                # Cambiar el tipo de divisores para permitir la mejor división\n)\n\n\n\n# Entrenar el modelo con los datos de entrenamiento\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\n# Calcular el AUC\nauc = roc_auc_score(y_test, y_test_tree)\nprint(f\"AUC: {auc}\")\n\n# Calcular Cohen's Kappa\nkappa = cohen_kappa_score(y_test, y_test_tree)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.388499Z","iopub.execute_input":"2025-03-01T20:57:51.388825Z","iopub.status.idle":"2025-03-01T20:57:51.426336Z","shell.execute_reply.started":"2025-03-01T20:57:51.388789Z","shell.execute_reply":"2025-03-01T20:57:51.425231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra un rendimiento muy bueno, con una **precisión** de 0.94 y un **recall** bien equilibrado entre las dos clases, destacando un **f1-score** de 0.92 para la clase 1. Aunque la clase 0 tiene un **recall** ligeramente superior (0.97 frente a 0.88), ambos valores son bastante altos, lo que refleja un buen desempeño en la clasificación. El **accuracy** de 0.94 confirma que el modelo es robusto y consistente en general. La **AUC** de 0.93 indica una buena capacidad de discriminación entre las clases, y el **Cohen's Kappa** de 0.87 sugiere una alta concordancia entre las predicciones y las etiquetas reales, lo que es un indicativo de un modelo fiable.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"x.radius_mean\": [14.0, 15.5, 13.2, 14.5, 15.0, 13.8, 14.2, 16.1, 15.3, 14.6],\n    \"x.texture_mean\": [19.0, 20.3, 18.5, 17.2, 21.1, 20.0, 18.8, 19.5, 20.2, 19.3],\n    \"x.perimeter_mean\": [85.0, 90.5, 80.3, 84.6, 89.7, 82.1, 86.4, 88.9, 87.5, 85.3],\n    \"x.area_mean\": [500.0, 550.2, 480.5, 510.6, 545.0, 495.0, 520.1, 530.4, 515.3, 505.2],\n    \"x.smoothness_mean\": [0.1, 0.12, 0.09, 0.11, 0.1, 0.08, 0.1, 0.13, 0.12, 0.1],\n    \"x.compactness_mean\": [0.02, 0.03, 0.025, 0.021, 0.03, 0.015, 0.02, 0.03, 0.02, 0.022],\n    \"x.concavity_mean\": [0.05, 0.07, 0.06, 0.055, 0.065, 0.045, 0.05, 0.06, 0.055, 0.05],\n    \"x.concave_pts_mean\": [0.03, 0.035, 0.02, 0.04, 0.03, 0.025, 0.03, 0.03, 0.025, 0.03],\n    \"x.symmetry_mean\": [0.18, 0.2, 0.17, 0.19, 0.18, 0.17, 0.18, 0.21, 0.19, 0.18],\n    \"x.fractal_dim_mean\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.046, 0.047, 0.05, 0.048, 0.05],\n    \"x.radius_se\": [0.03, 0.04, 0.02, 0.03, 0.04, 0.02, 0.03, 0.02, 0.03, 0.04],\n    \"x.texture_se\": [0.04, 0.05, 0.03, 0.04, 0.05, 0.03, 0.04, 0.03, 0.05, 0.04],\n    \"x.perimeter_se\": [0.12, 0.13, 0.1, 0.11, 0.12, 0.09, 0.11, 0.12, 0.1, 0.11],\n    \"x.area_se\": [30.0, 35.2, 28.5, 32.1, 33.5, 29.3, 30.2, 31.6, 32.8, 30.5],\n    \"x.smoothness_se\": [0.002, 0.0025, 0.0018, 0.0022, 0.002, 0.0019, 0.0021, 0.0023, 0.0021, 0.002],\n    \"x.compactness_se\": [0.001, 0.0015, 0.0012, 0.0011, 0.0013, 0.001, 0.0011, 0.0013, 0.0012, 0.0011],\n    \"x.concavity_se\": [0.0025, 0.003, 0.0027, 0.0026, 0.0031, 0.0023, 0.0025, 0.0028, 0.0026, 0.0027],\n    \"x.concave_pts_se\": [0.001, 0.0012, 0.0009, 0.001, 0.0011, 0.0008, 0.001, 0.0011, 0.001, 0.0009],\n    \"x.symmetry_se\": [0.008, 0.01, 0.009, 0.0085, 0.009, 0.008, 0.0085, 0.009, 0.0087, 0.008],\n    \"x.fractal_dim_se\": [0.003, 0.0035, 0.0028, 0.0032, 0.0031, 0.0029, 0.003, 0.0031, 0.0032, 0.003],\n    \"x.radius_worst\": [17.0, 18.5, 16.5, 17.8, 18.3, 16.9, 17.4, 18.7, 17.9, 17.2],\n    \"x.texture_worst\": [22.0, 23.3, 21.8, 22.5, 23.1, 22.3, 21.9, 23.0, 22.8, 22.1],\n    \"x.perimeter_worst\": [110.0, 120.3, 115.2, 113.5, 119.4, 114.6, 117.5, 120.0, 118.2, 115.8],\n    \"x.area_worst\": [800.0, 850.5, 780.3, 800.2, 830.0, 790.1, 810.5, 830.4, 820.2, 800.5],\n    \"x.smoothness_worst\": [0.13, 0.14, 0.12, 0.13, 0.14, 0.13, 0.13, 0.14, 0.13, 0.12],\n    \"x.compactness_worst\": [0.03, 0.035, 0.031, 0.028, 0.032, 0.03, 0.029, 0.031, 0.03, 0.029],\n    \"x.concavity_worst\": [0.07, 0.08, 0.075, 0.071, 0.078, 0.073, 0.074, 0.079, 0.076, 0.075],\n    \"x.concave_pts_worst\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.04, 0.045, 0.06, 0.048, 0.05],\n    \"x.symmetry_worst\": [0.22, 0.23, 0.21, 0.22, 0.23, 0.22, 0.21, 0.22, 0.22, 0.21],\n    \"x.fractal_dim_worst\": [0.05, 0.06, 0.048, 0.05, 0.055, 0.051, 0.052, 0.05, 0.053, 0.054]\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = tree_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.427914Z","iopub.execute_input":"2025-03-01T20:57:51.428431Z","iopub.status.idle":"2025-03-01T20:57:51.457123Z","shell.execute_reply.started":"2025-03-01T20:57:51.428386Z","shell.execute_reply":"2025-03-01T20:57:51.455914Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diabetes con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"# Preparación de los datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',           # Usar 'entropy' en lugar de 'gini' para mejorar la selección de características\n    max_depth=10,                  # Limitar la profundidad máxima para evitar el sobreajuste\n    min_samples_split=4,           # Reducir el número mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=4,            # Reducir el número de muestras mínimas por hoja para mejorar la capacidad de generalización\n    max_features='sqrt',           # Usar la raíz cuadrada del número de características para reducir la complejidad del modelo\n    class_weight='balanced'        # Ajustar el peso de las clases para manejar cualquier desbalance entre clases\n)\nmodelo = \"Árbol de Decisión\"\n\n# Entrenamiento del modelo\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_train, y_train_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_tree)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.458369Z","iopub.execute_input":"2025-03-01T20:57:51.458733Z","iopub.status.idle":"2025-03-01T20:57:51.505863Z","shell.execute_reply.started":"2025-03-01T20:57:51.458705Z","shell.execute_reply":"2025-03-01T20:57:51.504763Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados indican que el modelo de Árbol de Decisión está logrando una precisión moderada del 70%, con un AUC relativamente alto de 0.87, lo que sugiere que el modelo tiene un buen rendimiento en la clasificación general. Sin embargo, hay un desequilibrio en la clasificación entre las clases. La precisión para la clase 0 es más alta (0.80), mientras que la precisión para la clase 1 es más baja (0.57). El recall para la clase 1 (0.69) es más alto que para la clase 0 (0.71), lo que indica que el modelo tiene más éxito en detectar instancias de la clase 1, aunque a costa de una menor precisión.\n\nEl Cohen's Kappa de 0.71 indica un acuerdo bastante bueno entre las predicciones del modelo y las etiquetas reales, lo que sugiere que el modelo está realizando una clasificación coherente.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"# Preparación de los datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='gini',              # Usar 'gini' para una selección más robusta de las características\n    max_depth=12,                  # Limitar la profundidad para evitar sobreajuste\n    min_samples_split=6,           # Ajustar el mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=6,            # Asegurar que cada hoja tenga al menos 6 muestras para evitar sobreajuste\n    max_features='sqrt',           # Utilizar la raíz cuadrada de las características para reducir la complejidad\n    class_weight='balanced'  # Ajustar los pesos de las clases para manejar mejor el desequilibrio\n)\nmodelo = \"Árbol de Decisión\"\n\n# Entrenamiento del modelo\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_train, y_train_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_tree)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.507139Z","iopub.execute_input":"2025-03-01T20:57:51.507475Z","iopub.status.idle":"2025-03-01T20:57:51.541611Z","shell.execute_reply.started":"2025-03-01T20:57:51.507450Z","shell.execute_reply":"2025-03-01T20:57:51.540404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados indican que el modelo de Árbol de Decisión tiene un rendimiento moderado. La precisión para la clase 0 es bastante buena (0.77), pero la precisión para la clase 1 es baja (0.51), lo que refleja un claro desequilibrio en la clasificación entre las clases. El recall para la clase 1 es relativamente bueno (0.65), lo que significa que el modelo tiene una capacidad decente para identificar las instancias de la clase positiva, aunque aún hay margen de mejora en cuanto a precisión.\n\nLa AUC de 0.84 indica que el modelo tiene una buena capacidad para diferenciar entre las clases, lo que es positivo, pero la diferencia en la precisión y el recall sugiere que el modelo puede no estar equilibrando bien las clases, lo que es un desafío común en problemas con clases desbalanceadas.\n\nEl Cohen's Kappa de 0.67 muestra un acuerdo moderado entre las predicciones del modelo y las etiquetas reales, pero todavía hay espacio para mejorar la coherencia del modelo.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"# Preparación de los datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Crear el modelo de Árbol de Decisión con hiperparámetros ajustados\ntree_model = DecisionTreeClassifier(\n    random_state=42,\n    criterion='entropy',             # Usar 'entropy' para mejorar la selección de características\n    max_depth=10,                    # Limitar la profundidad para prevenir sobreajuste\n    min_samples_split=4,             # Reducir el mínimo de muestras necesarias para dividir un nodo\n    min_samples_leaf=4,              # Reducir el número de muestras mínimas por hoja para mejorar la capacidad de predicción\n    max_features='log2',             # Utilizar log2 de características para una mejor selección\n    class_weight='balanced'          # Ajustar el peso de las clases para manejar el desbalance\n)\nmodelo = \"Árbol de Decisión\"\n\n# Entrenamiento del modelo\ntree_model.fit(X_train, y_train)\n\n# Realizar las predicciones\ny_train_tree = tree_model.predict(X_train)\ny_test_tree = tree_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_tree))\n\nauc = roc_auc_score(y_train, y_train_tree)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_tree)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.542763Z","iopub.execute_input":"2025-03-01T20:57:51.543170Z","iopub.status.idle":"2025-03-01T20:57:51.578884Z","shell.execute_reply.started":"2025-03-01T20:57:51.543140Z","shell.execute_reply":"2025-03-01T20:57:51.577868Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo ha mostrado una precisión relativamente buena para la clase 0 (0.81), pero sigue habiendo un desbalance, ya que la precisión para la clase 1 sigue siendo baja (0.53). A pesar de esto, el recall de la clase 1 es bastante bueno (0.73), lo que indica que el modelo tiene una capacidad adecuada para identificar correctamente las instancias de la clase positiva, aunque sacrificando algo de precisión.\n\nLa AUC de 0.88 refleja que el modelo tiene una buena capacidad general para distinguir entre las clases, pero el desbalance entre las clases sigue afectando el rendimiento en términos de precisión. El Cohen's Kappa de 0.72 sugiere un buen nivel de acuerdo entre las predicciones y las etiquetas reales, lo que implica que el modelo está haciendo predicciones más consistentes que al principio, aunque aún tiene espacio para mejorar en términos de equilibrio entre clases.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"Pregnancies\": [6, 14, 10, 7, 6, 10, 10, 3, 7, 2],\n    \"Glucose\": [122, 71, 157, 107, 199, 90, 127, 91, 158, 118],\n    \"BloodPressure\": [108, 91, 109, 64, 111, 111, 96, 111, 100, 104],\n    \"SkinThickness\": [12, 46, 16, 30, 18, 48, 27, 13, 34, 23],\n    \"Insulin\": [261, 796, 365, 584, 359, 111, 386, 474, 447, 528],\n    \"BMI\": [40.50, 22.68, 28.56, 22.92, 38.39, 29.48, 23.61, 33.33, 18.85, 40.74],\n    \"DiabetesPedigreeFunction\": [0.90, 0.79, 1.85, 1.45, 0.65, 1.14, 1.04, 1.92, 1.69, 1.49],\n    \"Age\": [67, 44, 46, 45, 65, 61, 49, 35, 65, 21],\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Asegúrate de que las columnas del DataFrame coincidan con las de los datos de entrenamiento\ndf_scaled = scaler.transform(df)\n\n# Realizar las predicciones\nrandom_predictions = tree_model.predict(df_scaled)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.579902Z","iopub.execute_input":"2025-03-01T20:57:51.580204Z","iopub.status.idle":"2025-03-01T20:57:51.596661Z","shell.execute_reply.started":"2025-03-01T20:57:51.580181Z","shell.execute_reply":"2025-03-01T20:57:51.595562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Bosques Aleatorios\n\nLos bosques aleatorios (Random Forest) son un conjunto de algoritmos de aprendizaje supervisado utilizados para tareas de clasificación y regresión. Se basan en la combinación de múltiples árboles de decisión independientes para mejorar la precisión y reducir el riesgo de sobreajuste (overfitting) que puede ocurrir en un solo árbol de decisión. Cada árbol en el bosque se entrena con un subconjunto aleatorio de los datos de entrenamiento y, en cada división de nodo, se selecciona un subconjunto aleatorio de características para evitar la correlación entre los árboles.\n\nEl algoritmo de bosques aleatorios es especialmente eficaz en escenarios con grandes cantidades de datos y características, y se destaca por su capacidad para manejar tanto datos numéricos como categóricos. Además, la naturaleza del modelo permite una evaluación precisa de la importancia de las características, lo que facilita la interpretación y selección de variables relevantes.\n\nLos bosques aleatorios tienden a ser muy robustos y no requieren un ajuste excesivo de hiperparámetros, lo que los convierte en una opción popular para muchos problemas de aprendizaje supervisado, especialmente cuando la precisión es más importante que la interpretabilidad.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset Bosques Aleatorios","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nrf_model = RandomForestClassifier()\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:51.597843Z","iopub.execute_input":"2025-03-01T20:57:51.598265Z","iopub.status.idle":"2025-03-01T20:57:52.596784Z","shell.execute_reply.started":"2025-03-01T20:57:51.598229Z","shell.execute_reply":"2025-03-01T20:57:52.595435Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Este modelo de Bosques Aleatorios es altamente efectivo para la detección de phishing. Tiene un balance casi perfecto entre precisión y recall, minimizando tanto falsos positivos como falsos negativos. El alto AUC y Kappa refuerzan su fiabilidad.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del vino con Bosques Aleatorios","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nrf_model = RandomForestClassifier()\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:52.598057Z","iopub.execute_input":"2025-03-01T20:57:52.598449Z","iopub.status.idle":"2025-03-01T20:57:52.950597Z","shell.execute_reply.started":"2025-03-01T20:57:52.598408Z","shell.execute_reply":"2025-03-01T20:57:52.949343Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de clasificación de vinos muestra un rendimiento aceptable, con una precisión del 74%-81% y un recall del 76%-79%, logrando un **78% de accuracy**. Sin embargo, los valores de **AUC y Cohen's Kappa en 1.0** son inusualmente altos, lo que sugiere un posible **sobreajuste** o **fuga de datos** en el entrenamiento. Esto podría indicar que el modelo ha memorizado los datos en lugar de generalizar correctamente.","metadata":{}},{"cell_type":"markdown","source":"## Diagnostico del cancer de mama con Bosques Aleatorios","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nrf_model = RandomForestClassifier()\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:52.951832Z","iopub.execute_input":"2025-03-01T20:57:52.952262Z","iopub.status.idle":"2025-03-01T20:57:53.246870Z","shell.execute_reply.started":"2025-03-01T20:57:52.952223Z","shell.execute_reply":"2025-03-01T20:57:53.245863Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de **Bosques Aleatorios** para detección de cáncer de mama muestra un rendimiento excelente, con una **precisión del 95%**, un **AUC perfecto de 1.0** y un **Cohen’s Kappa de 1.0**, lo que indica una clasificación impecable sin sesgo aleatorio. La alta precisión y recall en ambas clases sugieren que el modelo detecta con fiabilidad tanto casos positivos como negativos, aunque el **recall del 88% en la clase 1** (casos positivos) sugiere que algunos casos podrían no ser detectados.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con Bosques Aleatorios","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo\nrf_model = RandomForestClassifier()\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:53.247778Z","iopub.execute_input":"2025-03-01T20:57:53.248037Z","iopub.status.idle":"2025-03-01T20:57:53.510604Z","shell.execute_reply.started":"2025-03-01T20:57:53.248016Z","shell.execute_reply":"2025-03-01T20:57:53.509529Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo presenta un **rendimiento aceptable**, con una **accuracy del 75%** y una precisión mayor en la clase **0 (no diabetes, 80%)** que en la clase **1 (diabetes, 67%)**. Sin embargo, la sensibilidad para detectar casos positivos (recall de 62%) es relativamente baja, lo que indica que **puede estar pasando por alto algunos casos de diabetes**.  \n\nEl principal problema es que el **AUC y Cohen’s Kappa son 1.0**, lo cual es extremadamente inusual y sugiere un **sobreajuste severo o fuga de datos**.","metadata":{}},{"cell_type":"markdown","source":"## Análisis Comparativo del Algoritmo en los Diferentes Datasets\n\n| **Modelo**             | **Accuracy** | **Precisión (0 / 1)** | **Recall (0 / 1)** | **F1-Score (0 / 1)** | **AUC** | **Cohen's Kappa** | **Observaciones** |\n|------------------------|-------------|------------------------|--------------------|----------------------|--------|------------------|------------------|\n| **Diabetes**           | 0.75        | 0.80 / 0.67            | 0.83 / 0.62        | 0.81 / 0.64          | **1.0** | **1.0**          | Rendimiento moderado, pero AUC y Kappa en 1.0 indican posible sobreajuste o fuga de datos. |\n| **Cáncer de mama**     | **0.95**    | 0.93 / 0.97            | 0.99 / 0.88        | 0.96 / 0.93          | **1.0** | **1.0**          | Muy buen rendimiento, pero el AUC y Kappa perfectos pueden indicar sobreajuste. |\n| **Calidad del vino**   | 0.78        | 0.74 / 0.81            | 0.76 / 0.79        | 0.75 / 0.80          | **1.0** | **1.0**          | Rendimiento decente, pero AUC y Kappa perfectos sugieren sobreajuste. |\n| **Detección de phishing** | **0.97**    | 0.97 / 0.97            | 0.96 / 0.98        | 0.96 / 0.97          | **0.99** | **0.98**         | Excelente rendimiento y métricas realistas, sin indicios de sobreajuste extremo. |\n\n\n- El modelo de detección de phishing tiene el mejor rendimiento equilibrado, con alta precisión y recall, sin signos evidentes de sobreajuste. \n\n- En contraste, los modelos de diabetes, cáncer de mama y calidad del vino muestran AUC y Kappa de 1.0, lo que sugiere posible sobreajuste o fuga de datos.","metadata":{}},{"cell_type":"markdown","source":"## Hiperparámetros de Random Forest\n\n1. **n_estimators**: El número de árboles en el bosque.\n\n2. **max_depth**: La profundidad máxima de cada árbol.\n\n3. **min_samples_split**: El número mínimo de muestras requeridas para dividir un nodo.\n\n4. **min_samples_leaf**: El número mínimo de muestras que deben estar presentes en una hoja.\n\n5. **max_features**: El número máximo de características a considerar para dividir un nodo.\n\n6. **max_samples**: El número máximo de muestras que se utilizarán para entrenar cada árbol (puede ser un porcentaje).\n\n7. **bootstrap**: Si se utiliza muestreo con reemplazo (True) o no (False) para crear los subconjuntos de datos de entrenamiento.\n\n8. **oob_score**: Si se utiliza la puntuación de los datos fuera de la bolsa (out-of-bag) para evaluar el rendimiento del modelo.\n\n9. **criterion**: El criterio de división, que puede ser 'gini' para la impureza de Gini o 'entropy' para la ganancia de \ninformación.\n\n10. **n_jobs**: El número de trabajos (procesadores) a usar para entrenar el modelo en paralelo.\n\n11. **random_state**: La semilla para la inicialización del generador de números aleatorios (para la reproducibilidad).\n\n12. **warm_start**: Si se deben reutilizar los árboles entrenados anteriormente en lugar de entrenar desde cero.\n\n13. **class_weight**: Para ajustar el peso de las clases en un problema desbalanceado.\n\n14. **verbose**: Nivel de verbosidad para mostrar mensajes durante el entrenamiento.\n\n15. **max_leaf_nodes**: El número máximo de nodos hoja en el árbol.\n\n16. **min_impurity_decrease**: La disminución mínima de la impureza para realizar una división.\n","metadata":{}},{"cell_type":"markdown","source":"## Phishing Bosques Aleatorios con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo con hiperparámetros añadidos\nrf_model = RandomForestClassifier(\n    n_estimators=100,          # Número de árboles\n    max_depth=10,              # Profundidad máxima de los árboles\n    min_samples_split=4,       # Mínimo número de muestras para dividir un nodo\n    min_samples_leaf=2,        # Mínimo número de muestras en una hoja\n    max_features='sqrt',       # Número máximo de características a considerar para cada división\n    bootstrap=True,            # Usar muestreo con reemplazo\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Semilla para reproducibilidad\n)\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:53.511652Z","iopub.execute_input":"2025-03-01T20:57:53.512098Z","iopub.status.idle":"2025-03-01T20:57:54.128646Z","shell.execute_reply.started":"2025-03-01T20:57:53.512069Z","shell.execute_reply":"2025-03-01T20:57:54.127397Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo de Random Forest muestra un buen rendimiento, con una alta precisión, recall y f1-score, especialmente en la clase positiva (1), donde tiene un recall del 97%, lo que indica que está muy bien capacitado para detectar correctamente las muestras positivas. La precisión también es alta, con un valor de 0.96 en general, lo que demuestra un buen equilibrio entre ambas clases. Además, el AUC de 0.96 y el Cohen's Kappa de 0.91 sugieren que el modelo tiene una capacidad muy sólida para clasificar correctamente, con una mínima discordancia entre las predicciones y las etiquetas reales.","metadata":{}},{"cell_type":"markdown","source":"## Phishing Bosques Aleatorios con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=200,          # Aumentar el número de árboles para mejorar la robustez del modelo\n    max_depth=15,              # Aumentar la profundidad para permitir árboles más complejos\n    min_samples_split=10,      # Aumentar el número mínimo de muestras para una división para evitar dividir demasiado pronto\n    min_samples_leaf=4,        # Aumentar el número mínimo de muestras en las hojas para evitar overfitting\n    max_features='log2',       # Usar log2 características, lo que podría dar más variabilidad y robustez\n    bootstrap=True,            # Usar muestreo con reemplazo\n    n_jobs=-1,                 # Utilizar todos los núcleos\n    random_state=42            # Semilla para reproducibilidad\n)\n\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:54.129724Z","iopub.execute_input":"2025-03-01T20:57:54.130121Z","iopub.status.idle":"2025-03-01T20:57:55.293531Z","shell.execute_reply.started":"2025-03-01T20:57:54.130092Z","shell.execute_reply":"2025-03-01T20:57:55.292254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo ha mejorado notablemente con respecto al ajuste anterior. El recall de la clase positiva (1) ha aumentado a 98%, lo que indica que ahora el modelo es aún más eficiente en la detección de los casos positivos. La precisión se mantiene bastante alta para ambas clases, con un f1-score equilibrado en torno a 0.96 para ambas clases. Además, el AUC de 0.96 y el Cohen's Kappa de 0.93 sugieren una mayor capacidad del modelo para clasificar correctamente los ejemplos, con menos discrepancias en las predicciones. En general, el modelo tiene un excelente desempeño, y está bien balanceado entre precisión y recall, con un rendimiento robusto en ambas clases.","metadata":{}},{"cell_type":"markdown","source":"## Phishing Bosques Aleatorios con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=300,          # Aumentar el número de árboles para mayor estabilidad\n    max_depth=20,              # Permitir una mayor profundidad para mejorar la capacidad de aprendizaje\n    min_samples_split=20,      # Aumentar el número mínimo de muestras para dividir un nodo para evitar el sobreajuste\n    min_samples_leaf=5,        # Aumentar el número mínimo de muestras por hoja para evitar dividir demasiado finamente\n    max_features='sqrt',       # Usar la cantidad máxima de características posibles (raíz cuadrada de las características)\n    bootstrap=True,            # Usar muestreo con reemplazo\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Para mantener la reproducibilidad\n)\n\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:55.294807Z","iopub.execute_input":"2025-03-01T20:57:55.295265Z","iopub.status.idle":"2025-03-01T20:57:57.048969Z","shell.execute_reply.started":"2025-03-01T20:57:55.295233Z","shell.execute_reply":"2025-03-01T20:57:57.047775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sigue mostrando un excelente rendimiento con un equilibrio entre precisión y recall en ambas clases. El recall de la clase positiva (1) sigue siendo alto, alcanzando el 97%, lo que indica una buena capacidad para identificar correctamente las muestras positivas. La precisión se mantiene sólida en ambas clases, con un f1-score de 0.96. Además, el AUC de 0.96 y el Cohen's Kappa de 0.92 sugieren que el modelo tiene una capacidad de clasificación robusta, con una mínima discrepancia entre las predicciones y las etiquetas reales. En general, el modelo es muy fiable y equilibrado.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"UsingIP\": np.random.choice([0, 1], 10),\n    \"LongURL\": np.random.choice([0, 1], 10),\n    \"ShortURL\": np.random.choice([0, 1], 10),\n    \"Symbol@\": np.random.choice([0, 1], 10),\n    \"Redirecting//\": np.random.choice([0, 1], 10),\n    \"PrefixSuffix-\": np.random.choice([0, 1], 10),\n    \"SubDomains\": np.random.choice([0, 1], 10),\n    \"HTTPS\": np.random.choice([0, 1], 10),\n    \"DomainRegLen\": np.random.randint(5, 15, 10),\n    \"Favicon\": np.random.choice([0, 1], 10),\n    \"NonStdPort\": np.random.choice([0, 1], 10),\n    \"HTTPSDomainURL\": np.random.choice([0, 1], 10),\n    \"RequestURL\": np.random.choice([0, 1], 10),\n    \"AnchorURL\": np.random.choice([0, 1], 10),\n    \"LinksInScriptTags\": np.random.choice([0, 1], 10),\n    \"ServerFormHandler\": np.random.choice([0, 1], 10),\n    \"InfoEmail\": np.random.choice([0, 1], 10),\n    \"AbnormalURL\": np.random.choice([0, 1], 10),\n    \"WebsiteForwarding\": np.random.choice([0, 1], 10),\n    \"StatusBarCust\": np.random.choice([0, 1], 10),\n    \"DisableRightClick\": np.random.choice([0, 1], 10),\n    \"UsingPopupWindow\": np.random.choice([0, 1], 10),\n    \"IframeRedirection\": np.random.choice([0, 1], 10),\n    \"AgeofDomain\": np.random.randint(1, 20, 10),\n    \"DNSRecording\": np.random.choice([0, 1], 10),\n    \"WebsiteTraffic\": np.random.randint(1000, 10000, 10),\n    \"PageRank\": np.random.randint(0, 10, 10),\n    \"GoogleIndex\": np.random.randint(0, 1000, 10),\n    \"LinksPointingToPage\": np.random.randint(0, 100, 10),\n    \"StatsReport\": np.random.choice([0, 1], 10),\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = rf_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:57.050027Z","iopub.execute_input":"2025-03-01T20:57:57.050417Z","iopub.status.idle":"2025-03-01T20:57:57.152025Z","shell.execute_reply.started":"2025-03-01T20:57:57.050389Z","shell.execute_reply":"2025-03-01T20:57:57.150706Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calidad del vino bosques aleatorios con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score\nimport numpy as np\nimport tensorflow as tf\nimport random\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo con hiperparámetros añadidos\nrf_model = RandomForestClassifier(\n    n_estimators=200,          # Aumentar el número de árboles para mayor estabilidad\n    max_depth=15,              # Aumentar la profundidad máxima de los árboles para mejorar la capacidad de modelado\n    min_samples_split=10,      # Aumentar el número mínimo de muestras para dividir un nodo para evitar sobreajuste\n    min_samples_leaf=4,        # Aumentar el número mínimo de muestras por hoja para evitar que los árboles se ajusten demasiado\n    max_features='sqrt',       # Usar la raíz cuadrada del número de características disponibles para cada división\n    bootstrap=True,            # Usar muestreo con reemplazo\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Para asegurar que el modelo sea reproducible\n)\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:57.153763Z","iopub.execute_input":"2025-03-01T20:57:57.154537Z","iopub.status.idle":"2025-03-01T20:57:58.158825Z","shell.execute_reply.started":"2025-03-01T20:57:57.154493Z","shell.execute_reply":"2025-03-01T20:57:58.157845Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra un rendimiento razonablemente bueno, con un accuracy general del 78% y un AUC de 0.92, lo que indica una buena capacidad de clasificación, especialmente en términos de separar las dos clases. Sin embargo, hay un pequeño desbalance entre las clases en cuanto a recall y precision. La clase 0 tiene un recall de 79%, lo que es bastante bueno, pero su precision es un poco más baja, 73%. Por otro lado, la clase 1 tiene un precision de 82%, pero su recall es más bajo, 76%, lo que podría sugerir que el modelo está clasificando algunas instancias positivas como negativas. El Cohen's Kappa de 0.83 también refleja un buen nivel de acuerdo entre las predicciones y las etiquetas reales, pero aún hay espacio para mejorar, sobre todo en la precisión y el recall de ambas clases.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del vino bosques aleatorios con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score\nimport numpy as np\nimport tensorflow as tf\nimport random\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=300,          # Aumentar el número de árboles para mejorar la robustez y reducir el sesgo\n    max_depth=20,              # Permitir mayor profundidad para capturar relaciones más complejas\n    min_samples_split=15,      # Aumentar el número mínimo de muestras para dividir un nodo para evitar sobreajuste\n    min_samples_leaf=6,        # Aumentar el número mínimo de muestras por hoja para evitar que el modelo se ajuste demasiado\n    max_features='log2',       # Usar log2 de las características para mejorar la diversidad entre los árboles\n    bootstrap=True,            # Usar muestreo con reemplazo para obtener más robustez\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Para garantizar la reproducibilidad\n)\n\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:58.160220Z","iopub.execute_input":"2025-03-01T20:57:58.160748Z","iopub.status.idle":"2025-03-01T20:57:59.686870Z","shell.execute_reply.started":"2025-03-01T20:57:58.160713Z","shell.execute_reply":"2025-03-01T20:57:59.685537Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sigue mostrando un rendimiento sólido, con un accuracy del 77% y un AUC de 0.89, lo que indica que el modelo tiene una buena capacidad para diferenciar entre las clases. Sin embargo, las métricas de precision y recall siguen estando ligeramente desequilibradas entre las dos clases. La clase 0 tiene un precision de 73% y un recall de 77%, lo que sugiere que el modelo podría mejorar en términos de precisión para la clase 0, ya que hay más falsos positivos. La clase 1 tiene una precision de 81% y un recall de 77%, lo que implica que el modelo tiene una mejor capacidad para predecir correctamente los positivos, pero algunos falsos negativos siguen afectando el recall. El Cohen's Kappa de 0.79 indica que hay un buen acuerdo entre las predicciones y las etiquetas reales, pero aún puede haber margen para mejorar el modelo.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del vino bosques aleatorios con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score\nimport numpy as np\nimport tensorflow as tf\nimport random\n\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=400,          # Aumentar el número de árboles para reducir el sesgo y mejorar la estabilidad\n    max_depth=15,              # Reducir la profundidad máxima para evitar sobreajuste\n    min_samples_split=10,      # Mantener el mínimo número de muestras para dividir un nodo para evitar divisiones muy específicas\n    min_samples_leaf=5,        # Ajustar el número de muestras por hoja para evitar árboles demasiado profundos y especializados\n    max_features='sqrt',       # Usar la raíz cuadrada de las características para aumentar la diversidad entre los árboles\n    bootstrap=True,            # Usar muestreo con reemplazo para mayor robustez\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Asegurar que el modelo sea reproducible\n)\n\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:57:59.688127Z","iopub.execute_input":"2025-03-01T20:57:59.688570Z","iopub.status.idle":"2025-03-01T20:58:01.586020Z","shell.execute_reply.started":"2025-03-01T20:57:59.688533Z","shell.execute_reply":"2025-03-01T20:58:01.584860Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo ha mostrado un buen rendimiento general, con una **accuracy** sólida y un **AUC** alto, lo que sugiere que el modelo tiene una buena capacidad para distinguir entre las clases. Sin embargo, las métricas de **precision** y **recall** siguen reflejando un pequeño desequilibrio entre las clases. La clase 0 tiene un **precision** y **recall** algo más bajos en comparación con la clase 1, lo que indica que el modelo podría mejorar en la predicción precisa de la clase 0. Por otro lado, el **Cohen's Kappa** es bastante alto, lo que refleja un buen acuerdo entre las predicciones y las etiquetas reales. En general, el modelo es efectivo, pero algunos ajustes adicionales podrían mejorar aún más el rendimiento, especialmente en el balance entre las clases.","metadata":{}},{"cell_type":"code","source":"data = {'fixed acidity': ([10.35253554,  7.26347495,  6.67898833, 12.19280472, 13.38056873,\n        11.55031192, 14.06472709, 11.6747519 , 13.20290934,  9.2585812 ]),\n        'volatile acidity': ([0.12494187, 0.93639711, 0.60643566, 0.8658896 , 0.48623281,\n        0.73974801, 0.87882902, 0.48436769, 0.9797959 , 0.68827086]),\n        'citric acid': ([0.22042425, 0.02174948, 0.66092244, 0.21206596, 0.26902823,\n        0.79488973, 0.05962322, 0.33986682, 0.56810277, 0.6550574 ]),\n        'residual sugar': ([ 9.97329302, 11.46712616, 19.59321475, 15.21857218, 19.9362865 ,\n        18.29606054, 18.60545566,  2.16459   ,  0.49073062,  4.99290913]),\n        'chlorides': ([0.01276844, 0.02554124, 0.08449844, 0.09391178, 0.08946256,\n        0.01140122, 0.03637004, 0.08003057, 0.05379014, 0.08017591]),\n        'free sulfur dioxide': ([47, 19, 37, 37,  4, 10, 48,  1,  9, 43]),\n        'total sulfur dioxide': ([91, 74, 35, 70, 46, 88, 15, 23, 83, 79]),\n        'density': ([1.04725638, 1.02393862, 1.03270583, 1.04728879, 1.00306102,\n        1.01175424, 1.0054896 , 0.98394179, 0.98215251, 1.00903544]),\n        'pH': ([2.60416364, 2.74681535, 2.73456048, 3.0179527 , 3.45726089,\n        3.10749114, 2.766903  , 2.63933977, 2.95081405, 3.37045817]),\n        'sulphates': ([0.87631514, 0.51598346, 0.79518658, 0.66021614, 0.62282499,\n        0.32949315, 0.57303068, 0.32104167, 0.76850822, 0.78956107]),\n        'alcohol': ([ 8.42640967,  9.62703237, 13.70056614,  9.44443614, 11.41589419,\n        9.26896253,  9.24523951,  8.5906224 , 11.15167205, 11.59417586])}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = rf_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:01.587033Z","iopub.execute_input":"2025-03-01T20:58:01.587373Z","iopub.status.idle":"2025-03-01T20:58:01.697465Z","shell.execute_reply.started":"2025-03-01T20:58:01.587347Z","shell.execute_reply":"2025-03-01T20:58:01.696402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cancer de mama Bosques aleatorios con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo con hiperparámetros ajustados\nrf_model = RandomForestClassifier(\n    n_estimators=500,          # Aumentar el número de árboles para reducir el sesgo y mejorar la estabilidad\n    max_depth=20,              # Aumentar la profundidad para capturar más relaciones complejas\n    min_samples_split=10,      # Mantener el mínimo número de muestras para dividir un nodo para evitar divisiones muy específicas\n    min_samples_leaf=4,        # Asegurar que las hojas tengan un número adecuado de muestras para evitar sobreajuste\n    max_features='sqrt',       # Usar la raíz cuadrada de las características para aumentar la diversidad entre los árboles\n    bootstrap=True,            # Usar muestreo con reemplazo para mayor robustez\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Asegurar que el modelo sea reproducible\n)\n\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:01.698828Z","iopub.execute_input":"2025-03-01T20:58:01.699166Z","iopub.status.idle":"2025-03-01T20:58:03.727170Z","shell.execute_reply.started":"2025-03-01T20:58:01.699130Z","shell.execute_reply":"2025-03-01T20:58:03.726088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo ha mostrado un rendimiento muy sólido, con una accuracy del 94% y un AUC muy alto de 0.98, lo que indica que tiene una excelente capacidad para discriminar entre las dos clases. La clase 0 tiene una precision de 93% y un recall de 97%, lo que sugiere que el modelo es muy preciso en la predicción de esta clase, aunque podría mejorar ligeramente en la captura de algunos falsos negativos. La clase 1 tiene una precision de 95% y un recall de 88%, lo que muestra que el modelo tiene un rendimiento fuerte, pero algunos falsos negativos afectan ligeramente el recall. El Cohen's Kappa de 0.97 refleja un acuerdo excepcional entre las predicciones y las etiquetas reales, lo que indica que el modelo es muy confiable. En general, el modelo tiene un rendimiento excelente, pero podría beneficiarse de un enfoque para mejorar el recall de la clase 1 sin sacrificar mucho en precision.","metadata":{}},{"cell_type":"markdown","source":"## Cancer de mama Bosques aleatorios con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=600,          # Aumentar el número de árboles para mejorar la estabilidad y reducir el sesgo\n    max_depth=15,              # Limitar la profundidad para evitar el sobreajuste\n    min_samples_split=5,       # Reducir el mínimo número de muestras para dividir un nodo y permitir una mayor granularidad\n    min_samples_leaf=2,        # Reducir el número de muestras por hoja para mejorar el ajuste en pequeños subconjuntos\n    max_features='sqrt',       # Usar todas las características disponibles para los árboles\n    bootstrap=True,            # Usar muestreo con reemplazo para mejorar la robustez\n    class_weight='balanced',   # Ajustar el peso de las clases para manejar el desbalanceo entre clases\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador para acelerar el entrenamiento\n    random_state=42            # Asegurar que el modelo sea reproducible\n)\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:03.728138Z","iopub.execute_input":"2025-03-01T20:58:03.728516Z","iopub.status.idle":"2025-03-01T20:58:06.019786Z","shell.execute_reply.started":"2025-03-01T20:58:03.728489Z","shell.execute_reply":"2025-03-01T20:58:06.018631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo ha alcanzado un rendimiento sobresaliente, con una accuracy del 96% y un AUC de 0.99, lo que indica una excelente capacidad de discriminación entre las dos clases. La precision y recall para ambas clases son muy altas, con la clase 0 mostrando un precision de 96% y recall de 97%, y la clase 1 con un precision de 95% y recall de 93%. Estos resultados sugieren que el modelo es muy efectivo para predecir ambas clases, logrando un buen balance entre precision y recall, lo que es especialmente importante en problemas desbalanceados. El Cohen's Kappa de 0.99 refleja una excelente concordancia entre las predicciones y las etiquetas reales, lo que demuestra la confiabilidad del modelo.","metadata":{}},{"cell_type":"markdown","source":"## Cancer de mama Bosques aleatorios con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=700,          # Aumentar el número de árboles para mejorar la estabilidad y reducir el sesgo aún más\n    max_depth=12,              # Limitar un poco más la profundidad para evitar el sobreajuste\n    min_samples_split=5,       # Mantener el número mínimo de muestras para dividir un nodo, permitiendo mayor granularidad\n    min_samples_leaf=1,        # Reducir aún más el número de muestras por hoja para mejorar el ajuste en pequeños subconjuntos\n    max_features='sqrt',       # Usar solo una parte de las características para cada árbol y aumentar la diversidad\n    bootstrap=True,            # Usar muestreo con reemplazo para mejorar la robustez del modelo\n    class_weight='balanced',   # Asegurar que las clases menos representadas no queden subrepresentadas\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador para acelerar el entrenamiento\n    random_state=42            # Asegurar que el modelo sea reproducible\n)\nmodelo = \"Bosques Aleatorios\"\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:06.020976Z","iopub.execute_input":"2025-03-01T20:58:06.021320Z","iopub.status.idle":"2025-03-01T20:58:08.835356Z","shell.execute_reply.started":"2025-03-01T20:58:06.021265Z","shell.execute_reply":"2025-03-01T20:58:08.834149Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo presenta un rendimiento sobresaliente, alcanzando una **accuracy** del 95% y un **AUC** de 0.997, lo que indica una excelente capacidad de discriminación entre las clases. La **precision** y **recall** son muy altas en ambas clases, con la clase 0 mostrando un **precision** de 95% y **recall** de 97%, y la clase 1 con un **precision** de 95% y **recall** de 91%. Este rendimiento equilibrado entre **precision** y **recall** demuestra que el modelo es eficaz para clasificar ambas clases. El **Cohen's Kappa** de 0.995 refleja una casi perfecta concordancia entre las predicciones y las etiquetas reales, confirmando que el modelo es altamente confiable y tiene un excelente desempeño general.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"x.radius_mean\": [14.0, 15.5, 13.2, 14.5, 15.0, 13.8, 14.2, 16.1, 15.3, 14.6],\n    \"x.texture_mean\": [19.0, 20.3, 18.5, 17.2, 21.1, 20.0, 18.8, 19.5, 20.2, 19.3],\n    \"x.perimeter_mean\": [85.0, 90.5, 80.3, 84.6, 89.7, 82.1, 86.4, 88.9, 87.5, 85.3],\n    \"x.area_mean\": [500.0, 550.2, 480.5, 510.6, 545.0, 495.0, 520.1, 530.4, 515.3, 505.2],\n    \"x.smoothness_mean\": [0.1, 0.12, 0.09, 0.11, 0.1, 0.08, 0.1, 0.13, 0.12, 0.1],\n    \"x.compactness_mean\": [0.02, 0.03, 0.025, 0.021, 0.03, 0.015, 0.02, 0.03, 0.02, 0.022],\n    \"x.concavity_mean\": [0.05, 0.07, 0.06, 0.055, 0.065, 0.045, 0.05, 0.06, 0.055, 0.05],\n    \"x.concave_pts_mean\": [0.03, 0.035, 0.02, 0.04, 0.03, 0.025, 0.03, 0.03, 0.025, 0.03],\n    \"x.symmetry_mean\": [0.18, 0.2, 0.17, 0.19, 0.18, 0.17, 0.18, 0.21, 0.19, 0.18],\n    \"x.fractal_dim_mean\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.046, 0.047, 0.05, 0.048, 0.05],\n    \"x.radius_se\": [0.03, 0.04, 0.02, 0.03, 0.04, 0.02, 0.03, 0.02, 0.03, 0.04],\n    \"x.texture_se\": [0.04, 0.05, 0.03, 0.04, 0.05, 0.03, 0.04, 0.03, 0.05, 0.04],\n    \"x.perimeter_se\": [0.12, 0.13, 0.1, 0.11, 0.12, 0.09, 0.11, 0.12, 0.1, 0.11],\n    \"x.area_se\": [30.0, 35.2, 28.5, 32.1, 33.5, 29.3, 30.2, 31.6, 32.8, 30.5],\n    \"x.smoothness_se\": [0.002, 0.0025, 0.0018, 0.0022, 0.002, 0.0019, 0.0021, 0.0023, 0.0021, 0.002],\n    \"x.compactness_se\": [0.001, 0.0015, 0.0012, 0.0011, 0.0013, 0.001, 0.0011, 0.0013, 0.0012, 0.0011],\n    \"x.concavity_se\": [0.0025, 0.003, 0.0027, 0.0026, 0.0031, 0.0023, 0.0025, 0.0028, 0.0026, 0.0027],\n    \"x.concave_pts_se\": [0.001, 0.0012, 0.0009, 0.001, 0.0011, 0.0008, 0.001, 0.0011, 0.001, 0.0009],\n    \"x.symmetry_se\": [0.008, 0.01, 0.009, 0.0085, 0.009, 0.008, 0.0085, 0.009, 0.0087, 0.008],\n    \"x.fractal_dim_se\": [0.003, 0.0035, 0.0028, 0.0032, 0.0031, 0.0029, 0.003, 0.0031, 0.0032, 0.003],\n    \"x.radius_worst\": [17.0, 18.5, 16.5, 17.8, 18.3, 16.9, 17.4, 18.7, 17.9, 17.2],\n    \"x.texture_worst\": [22.0, 23.3, 21.8, 22.5, 23.1, 22.3, 21.9, 23.0, 22.8, 22.1],\n    \"x.perimeter_worst\": [110.0, 120.3, 115.2, 113.5, 119.4, 114.6, 117.5, 120.0, 118.2, 115.8],\n    \"x.area_worst\": [800.0, 850.5, 780.3, 800.2, 830.0, 790.1, 810.5, 830.4, 820.2, 800.5],\n    \"x.smoothness_worst\": [0.13, 0.14, 0.12, 0.13, 0.14, 0.13, 0.13, 0.14, 0.13, 0.12],\n    \"x.compactness_worst\": [0.03, 0.035, 0.031, 0.028, 0.032, 0.03, 0.029, 0.031, 0.03, 0.029],\n    \"x.concavity_worst\": [0.07, 0.08, 0.075, 0.071, 0.078, 0.073, 0.074, 0.079, 0.076, 0.075],\n    \"x.concave_pts_worst\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.04, 0.045, 0.06, 0.048, 0.05],\n    \"x.symmetry_worst\": [0.22, 0.23, 0.21, 0.22, 0.23, 0.22, 0.21, 0.22, 0.22, 0.21],\n    \"x.fractal_dim_worst\": [0.05, 0.06, 0.048, 0.05, 0.055, 0.051, 0.052, 0.05, 0.053, 0.054]\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = rf_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:08.836508Z","iopub.execute_input":"2025-03-01T20:58:08.836812Z","iopub.status.idle":"2025-03-01T20:58:09.019241Z","shell.execute_reply.started":"2025-03-01T20:58:08.836786Z","shell.execute_reply":"2025-03-01T20:58:09.018164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diabetes Bosques aleatorios con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo con nuevos hiperparámetros\nrf_model = RandomForestClassifier(\n    n_estimators=500,          # Aumentar el número de árboles para mejorar la precisión\n    max_depth=10,              # Limitar la profundidad de los árboles para evitar sobreajuste\n    min_samples_split=8,       # Mantener el mínimo número de muestras para dividir un nodo\n    min_samples_leaf=4,        # Ajustar el número de muestras por hoja\n    max_features='sqrt',       # Usar la raíz cuadrada de las características para cada árbol\n    bootstrap=True,            # Usar muestreo con reemplazo para aumentar la robustez\n    class_weight='balanced',   # Asegurar que las clases desequilibradas no afecten el modelo\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador para acelerar el entrenamiento\n    random_state=42            # Asegurar que el modelo sea reproducible\n)\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:09.020266Z","iopub.execute_input":"2025-03-01T20:58:09.020588Z","iopub.status.idle":"2025-03-01T20:58:11.340549Z","shell.execute_reply.started":"2025-03-01T20:58:09.020563Z","shell.execute_reply":"2025-03-01T20:58:11.339428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo con la configuración actual muestra un buen rendimiento general, con una precisión del 77% y un AUC de aproximadamente 0.92, lo que indica que el modelo tiene una buena capacidad para discriminar entre las clases. Sin embargo, la precisión para la clase 1 (diabéticos) es un poco más baja en comparación con la clase 0 (no diabéticos), lo que sugiere que el modelo podría estar teniendo dificultades para identificar correctamente los casos positivos, a pesar de una recall razonable para la clase 1 (78%). Esto podría ser un indicativo de que el modelo necesita mejorar la clasificación de los casos positivos sin sacrificar demasiado la clasificación de la clase 0.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes Bosques aleatorios con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=600,          # Aumentar el número de árboles para mejorar la estabilidad\n    max_depth=8,               # Limitar la profundidad de los árboles para evitar sobreajuste\n    min_samples_split=10,      # Aumentar el número mínimo de muestras para dividir un nodo\n    min_samples_leaf=5,        # Ajustar el número de muestras por hoja\n    max_features='sqrt',       # Usar la raíz cuadrada de las características para cada árbol\n    bootstrap=True,            # Usar muestreo con reemplazo para mayor robustez\n    class_weight='balanced_subsample',  # Ajuste dinámico de los pesos de clase para equilibrar el desbalance\n    n_jobs=-1,                 # Utilizar todos los núcleos del procesador\n    random_state=42            # Asegurar que el modelo sea reproducible\n)\n\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:11.341747Z","iopub.execute_input":"2025-03-01T20:58:11.342059Z","iopub.status.idle":"2025-03-01T20:58:14.996697Z","shell.execute_reply.started":"2025-03-01T20:58:11.342031Z","shell.execute_reply":"2025-03-01T20:58:14.995558Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo sigue mostrando un rendimiento decente, con una precisión del 77% y un AUC de 0.89, lo que indica que tiene una buena capacidad discriminativa. Sin embargo, la precisión de la clase 1 (diabéticos) sigue siendo relativamente baja en comparación con la clase 0 (no diabéticos), lo que puede indicar que el modelo aún tiene dificultades para clasificar correctamente a los casos positivos. La recall de la clase 1 (78%) es razonablemente alta, lo que significa que el modelo es capaz de identificar una gran parte de los casos positivos, pero la precisión sigue siendo baja, lo que indica que también clasifica incorrectamente varios negativos como positivos.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes Bosques aleatorios con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"X = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(\n    n_estimators=700,          # Aumentar el número de árboles para mayor robustez\n    max_depth=10,              # Limitar la profundidad para evitar sobreajuste\n    min_samples_split=8,       # Menos muestras para dividir un nodo, mejorando la capacidad de generalización\n    min_samples_leaf=4,        # Aumentar el número mínimo de muestras por hoja para reducir el sobreajuste\n    max_features='sqrt',       # Seleccionar características al azar para cada árbol\n    bootstrap=True,            # Aumentar robustez con muestreo con reemplazo\n    class_weight='balanced',   # Asignar pesos equilibrados a las clases para mejorar el manejo del desbalanceo\n    n_jobs=-1,                 # Utilizar todos los núcleos disponibles\n    random_state=42            # Asegurar reproducibilidad\n)\n\n\n\n# Entrenar el modelo\nrf_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_RF = rf_model.predict(X_train)\ny_test_RF = rf_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_RF))\n\nauc = roc_auc_score(y_train, y_train_RF)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_RF)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:14.997790Z","iopub.execute_input":"2025-03-01T20:58:14.998155Z","iopub.status.idle":"2025-03-01T20:58:18.238555Z","shell.execute_reply.started":"2025-03-01T20:58:14.998128Z","shell.execute_reply":"2025-03-01T20:58:18.237065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = {\n    \"Pregnancies\": [6, 14, 10, 7, 6, 10, 10, 3, 7, 2],\n    \"Glucose\": [122, 71, 157, 107, 199, 90, 127, 91, 158, 118],\n    \"BloodPressure\": [108, 91, 109, 64, 111, 111, 96, 111, 100, 104],\n    \"SkinThickness\": [12, 46, 16, 30, 18, 48, 27, 13, 34, 23],\n    \"Insulin\": [261, 796, 365, 584, 359, 111, 386, 474, 447, 528],\n    \"BMI\": [40.50, 22.68, 28.56, 22.92, 38.39, 29.48, 23.61, 33.33, 18.85, 40.74],\n    \"DiabetesPedigreeFunction\": [0.90, 0.79, 1.85, 1.45, 0.65, 1.14, 1.04, 1.92, 1.69, 1.49],\n    \"Age\": [67, 44, 46, 45, 65, 61, 49, 35, 65, 21],\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = rf_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:18.240009Z","iopub.execute_input":"2025-03-01T20:58:18.240441Z","iopub.status.idle":"2025-03-01T20:58:18.514562Z","shell.execute_reply.started":"2025-03-01T20:58:18.240411Z","shell.execute_reply":"2025-03-01T20:58:18.512735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. k-Nearest Neighbors (kNN)\n\nEl algoritmo k-Nearest Neighbors (kNN) es un método de aprendizaje supervisado utilizado para tareas de clasificación y regresión. Se basa en la idea de que las instancias de datos similares se agrupan en el espacio de características. Al realizar una predicción para un nuevo dato, el modelo busca los \"k\" vecinos más cercanos en el conjunto de entrenamiento y hace una predicción en función de las etiquetas o valores de esos vecinos.\n\nEn clasificación, kNN asigna al nuevo dato la clase más frecuente entre los k vecinos más cercanos, mientras que en regresión, la predicción se obtiene como el promedio de los valores de los vecinos más cercanos. El valor de \"k\" es un hiperparámetro clave en este modelo, ya que influye directamente en la precisión del modelo; un valor muy pequeño puede resultar en un modelo sensible al ruido, mientras que un valor muy grande puede hacer que el modelo pierda detalles importantes.\n\nEl algoritmo kNN es intuitivo y fácil de implementar, y es eficaz en conjuntos de datos donde la relación entre las características y la etiqueta de salida es de naturaleza no lineal. Sin embargo, puede ser computacionalmente costoso, especialmente en conjuntos de datos grandes, ya que requiere calcular las distancias entre el nuevo dato y todas las instancias del conjunto de entrenamiento durante la predicción.\n\nUna de las principales ventajas de kNN es su capacidad para trabajar sin hacer suposiciones sobre la distribución de los datos, lo que lo convierte en un algoritmo flexible. Sin embargo, la eficiencia del algoritmo puede verse afectada cuando el número de características es muy alto, debido a la maldición de la dimensionalidad, lo que puede dificultar la identificación de los vecinos más cercanos.","metadata":{}},{"cell_type":"markdown","source":"## Phishing dataset con kNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN sin hiperparámetros\nknn_model = KNeighborsClassifier()\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:18.516894Z","iopub.execute_input":"2025-03-01T20:58:18.517244Z","iopub.status.idle":"2025-03-01T20:58:21.396658Z","shell.execute_reply.started":"2025-03-01T20:58:18.517217Z","shell.execute_reply":"2025-03-01T20:58:21.395452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo k-NN está funcionando de manera excelente, con una alta precisión y una gran capacidad de generalización. La AUC cercana a 1 y el Cohen’s Kappa alto indican que el modelo es fiable y efectivo en la clasificación de datos de phishing. No parece haber problemas graves de desbalanceo ni sesgo.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino con kNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN sin hiperparámetros\nknn_model = KNeighborsClassifier()\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:21.397954Z","iopub.execute_input":"2025-03-01T20:58:21.398299Z","iopub.status.idle":"2025-03-01T20:58:21.494550Z","shell.execute_reply.started":"2025-03-01T20:58:21.398251Z","shell.execute_reply":"2025-03-01T20:58:21.493123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo tiene un rendimiento moderado, con una precisión y recall equilibrados en ambas clases, pero con margen de mejora, ya que la exactitud global es del 67%. La AUC de 0.76 indica una capacidad aceptable de discriminación entre clases, mientras que el Cohen’s Kappa de 0.51 sugiere un acuerdo moderado entre las predicciones y las etiquetas reales.","metadata":{}},{"cell_type":"markdown","source":"## Cancer de mama con kNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN sin hiperparámetros\nknn_model = KNeighborsClassifier()\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:21.496087Z","iopub.execute_input":"2025-03-01T20:58:21.496558Z","iopub.status.idle":"2025-03-01T20:58:21.615674Z","shell.execute_reply.started":"2025-03-01T20:58:21.496520Z","shell.execute_reply":"2025-03-01T20:58:21.614406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo muestra un excelente desempeño con una precisión y recall altos en ambas clases, logrando una exactitud del 94%. La AUC de 0.93 indica una gran capacidad de discriminación entre clases, y el Cohen’s Kappa de 0.87 refleja un alto grado de acuerdo entre las predicciones y las etiquetas reales. En general, el modelo es confiable y bien equilibrado.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes con kNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN sin hiperparámetros\nknn_model = KNeighborsClassifier()\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:21.617200Z","iopub.execute_input":"2025-03-01T20:58:21.617610Z","iopub.status.idle":"2025-03-01T20:58:21.699270Z","shell.execute_reply.started":"2025-03-01T20:58:21.617579Z","shell.execute_reply":"2025-03-01T20:58:21.698069Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo tiene un rendimiento aceptable pero mejorable, con una precisión y recall más altos para la clase 0 en comparación con la clase 1, lo que sugiere un posible desequilibrio en la clasificación. La exactitud general del 66% y el Cohen’s Kappa de 0.54 indican un acuerdo moderado entre las predicciones y las etiquetas reales. La AUC de 0.76 muestra una capacidad razonable para diferenciar clases.","metadata":{}},{"cell_type":"markdown","source":"## Análisis Comparativo del Algoritmo en los Diferentes Datasets\n\n| Modelo            | Accuracy | AUC   | Cohen's Kappa | Mejor Clase (F1-Score) |\n|------------------|----------|--------|---------------|------------------------|\n| Diabetes        | 0.66     | 0.76   | 0.54          | 0 (0.73)               |\n| Cáncer de mama | 0.94     | 0.93   | 0.87          | 0 (0.95)               |\n| Calidad del vino | 0.67     | 0.76   | 0.51          | 1 (0.70)               |\n| Phishing        | 0.94     | 0.97   | 0.93          | 1 (0.95)               |\n\n\nEl modelo de phishing es el más preciso, con una accuracy del 94%, una AUC de 0.97 y un Cohen’s Kappa de 0.93, lo que indica un excelente desempeño. El modelo de cáncer de mama también obtiene muy buenos resultados, con métricas altas y una fuerte capacidad de clasificación. En cambio, los modelos de diabetes y calidad del vino muestran un rendimiento más bajo, con accuracies en torno al 66-67% y un Cohen’s Kappa cercano a 0.5, lo que indica un acuerdo moderado con las etiquetas reales.","metadata":{}},{"cell_type":"markdown","source":"## Hiperparámetros de k-NN:\n\n1. **`n_neighbors`**: Número de vecinos a considerar (valor de *k*).  \n2. **`weights`**: Método de ponderación de los vecinos.  \n   - `\"uniform\"` (todos los vecinos tienen el mismo peso).  \n   - `\"distance\"` (los vecinos más cercanos tienen más peso).  \n   - Función personalizada.  \n3. **`algorithm`**: Algoritmo para encontrar los vecinos más cercanos.  \n   - `\"auto\"` (elige el mejor automáticamente).  \n   - `\"ball_tree\"` (estructura eficiente para datos con muchas dimensiones).  \n   - `\"kd_tree\"` (bueno para dimensiones más bajas).  \n   - `\"brute\"` (búsqueda por fuerza bruta).  \n4. **`leaf_size`**: Tamaño de las hojas en *Ball Tree* y *KD Tree* (afecta velocidad y consumo de memoria).  \n5. **`metric`**: Distancia usada para calcular la similitud entre puntos.  \n   - `\"minkowski\"` (por defecto, con *p=2* equivale a distancia euclidiana).  \n   - `\"euclidean\"` (distancia euclidiana).  \n   - `\"manhattan\"` (distancia de Manhattan).  \n   - `\"chebyshev\"` (distancia máxima en cualquier dimensión).  \n   - Otras métricas personalizadas.  \n6. **`p`**: Parámetro para la distancia de Minkowski.  \n   - *p=1* → distancia de Manhattan.  \n   - *p=2* → distancia euclidiana.  \n7. **`n_jobs`**: Número de núcleos de CPU a utilizar para paralelizar la búsqueda de vecinos (solo aplicable en algunas implementaciones).  \n\nEstos hiperparámetros pueden ajustarse manualmente o mediante técnicas como **Grid Search** o **Random Search** para mejorar el rendimiento del modelo.","metadata":{}},{"cell_type":"markdown","source":"## Phishing kNN con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# n_neighbors=5: Usa 5 vecinos para la clasificación.\n# weights='distance': Vecinos más cercanos tienen mayor peso en la decisión.\n# metric='minkowski', p=2: Usa la distancia Euclidiana.\n# algorithm='auto': Deja que Scikit-learn elija el mejor algoritmo para la búsqueda de vecinos.\n\n# Crear el modelo k-NN con hiperparámetros ajustados\nknn_model = KNeighborsClassifier(n_neighbors=5,         # Usar 5 vecinos para la clasificación\n                                 weights='distance',    # Dar más peso a los vecinos más cercanos \n                                 metric='minkowski',p=2,# Usar la distancia Euclidiana\n                                 algorithm='auto')      # Dejar que Scikit-learn elija el mejor algoritmo\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:21.700346Z","iopub.execute_input":"2025-03-01T20:58:21.700708Z","iopub.status.idle":"2025-03-01T20:58:23.770746Z","shell.execute_reply.started":"2025-03-01T20:58:21.700668Z","shell.execute_reply":"2025-03-01T20:58:23.769448Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phishing kNN con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# n_neighbors=5: Usa 5 vecinos para la clasificación.\n# weights='distance': Vecinos más cercanos tienen mayor peso en la decisión.\n# metric='minkowski', p=2: Usa la distancia Euclidiana.\n# algorithm='auto': Deja que Scikit-learn elija el mejor algoritmo para la búsqueda de vecinos.\n\n# Crear el modelo k-NN con hiperparámetros ajustados\nknn_model = KNeighborsClassifier(n_neighbors=7,             # Usar 7 vecinos para la clasificación\n                                 weights='uniform',         # Todos los vecinos tienen el mismo peso\n                                 metric='manhattan',        # Usar la distancia de Manhattan\n                                 algorithm='ball_tree')     # Usar el algoritmo de Ball Tree\nmodelo = \"k-Nearest Neighbors\"\n\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:23.772015Z","iopub.execute_input":"2025-03-01T20:58:23.772491Z","iopub.status.idle":"2025-03-01T20:58:29.320073Z","shell.execute_reply.started":"2025-03-01T20:58:23.772459Z","shell.execute_reply":"2025-03-01T20:58:29.318903Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo mantiene un alto rendimiento con una precisión y recall equilibrados en ambas clases, logrando una exactitud del 95%. La AUC de 0.96 sigue indicando una buena capacidad para distinguir entre clases, aunque es ligeramente inferior a la versión anterior (0.99). El Cohen’s Kappa de 0.93 sigue reflejando una alta concordancia, aunque ha bajado un poco. Esto sugiere que el modelo sigue siendo sólido, pero podría beneficiarse de pequeños ajustes para mejorar la estabilidad y la capacidad de generalización.","metadata":{}},{"cell_type":"markdown","source":"## Phishing kNN con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = phishing.drop([\"class\"], axis=1)\ny = phishing[\"class\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# n_neighbors=5: Usa 5 vecinos para la clasificación.\n# weights='distance': Vecinos más cercanos tienen mayor peso en la decisión.\n# metric='minkowski', p=2: Usa la distancia Euclidiana.\n# algorithm='auto': Deja que Scikit-learn elija el mejor algoritmo para la búsqueda de vecinos.\n\nknn_model = KNeighborsClassifier(n_neighbors=9,         # Usar 9 vecinos para la clasificación\n                                weights='distance',     # Dar más peso a los vecinos más cercanos\n                                metric='euclidean',     # Usar la distancia Euclidiana\n                                leaf_size=30,           # Tamaño de hoja para el algoritmo de Ball Tree\n                                algorithm='auto')       # Dejar que Scikit-learn elija el mejor algoritmo\nmodelo = \"k-Nearest Neighbors\"\n\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:29.321256Z","iopub.execute_input":"2025-03-01T20:58:29.321659Z","iopub.status.idle":"2025-03-01T20:58:31.534159Z","shell.execute_reply.started":"2025-03-01T20:58:29.321624Z","shell.execute_reply":"2025-03-01T20:58:31.532561Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El algoritmo kNN está funcionando de manera excelente. Tiene un alto rendimiento en términos de precisión, recall, F1-score, AUC y Cohen's Kappa. No parece haber un desbalance significativo entre las clases, y el modelo es muy efectivo para clasificar correctamente las instancias en ambas clases.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"UsingIP\": np.random.choice([0, 1], 10),\n    \"LongURL\": np.random.choice([0, 1], 10),\n    \"ShortURL\": np.random.choice([0, 1], 10),\n    \"Symbol@\": np.random.choice([0, 1], 10),\n    \"Redirecting//\": np.random.choice([0, 1], 10),\n    \"PrefixSuffix-\": np.random.choice([0, 1], 10),\n    \"SubDomains\": np.random.choice([0, 1], 10),\n    \"HTTPS\": np.random.choice([0, 1], 10),\n    \"DomainRegLen\": np.random.randint(5, 15, 10),\n    \"Favicon\": np.random.choice([0, 1], 10),\n    \"NonStdPort\": np.random.choice([0, 1], 10),\n    \"HTTPSDomainURL\": np.random.choice([0, 1], 10),\n    \"RequestURL\": np.random.choice([0, 1], 10),\n    \"AnchorURL\": np.random.choice([0, 1], 10),\n    \"LinksInScriptTags\": np.random.choice([0, 1], 10),\n    \"ServerFormHandler\": np.random.choice([0, 1], 10),\n    \"InfoEmail\": np.random.choice([0, 1], 10),\n    \"AbnormalURL\": np.random.choice([0, 1], 10),\n    \"WebsiteForwarding\": np.random.choice([0, 1], 10),\n    \"StatusBarCust\": np.random.choice([0, 1], 10),\n    \"DisableRightClick\": np.random.choice([0, 1], 10),\n    \"UsingPopupWindow\": np.random.choice([0, 1], 10),\n    \"IframeRedirection\": np.random.choice([0, 1], 10),\n    \"AgeofDomain\": np.random.randint(1, 20, 10),\n    \"DNSRecording\": np.random.choice([0, 1], 10),\n    \"WebsiteTraffic\": np.random.randint(1000, 10000, 10),\n    \"PageRank\": np.random.randint(0, 10, 10),\n    \"GoogleIndex\": np.random.randint(0, 1000, 10),\n    \"LinksPointingToPage\": np.random.randint(0, 100, 10),\n    \"StatsReport\": np.random.choice([0, 1], 10),\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = knn_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:31.535569Z","iopub.execute_input":"2025-03-01T20:58:31.536016Z","iopub.status.idle":"2025-03-01T20:58:31.577502Z","shell.execute_reply.started":"2025-03-01T20:58:31.535975Z","shell.execute_reply":"2025-03-01T20:58:31.575658Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calidad del Vino kNN con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN con hiperparámetros\nknn_model = KNeighborsClassifier(\n    n_neighbors=5,          # Usar 5 vecinos para la clasificación\n    weights='uniform',      # Todos los vecinos tienen el mismo peso\n    algorithm='auto',       # Dejar que Scikit-learn elija el mejor algoritmo\n    leaf_size=30,           # Tamaño de hoja para el algoritmo de Ball Tree\n    p=2,                    # Usar la distancia Euclidiana       \n    metric='minkowski',     # Usar la distancia de Minkowski       \n    n_jobs=-1               # Usar todos los núcleos del procesador     \n)\n\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:31.578390Z","iopub.execute_input":"2025-03-01T20:58:31.578896Z","iopub.status.idle":"2025-03-01T20:58:31.709562Z","shell.execute_reply.started":"2025-03-01T20:58:31.578852Z","shell.execute_reply":"2025-03-01T20:58:31.708087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados obtenidos muestran que el modelo k-NN tiene un rendimiento moderado, con una exactitud (accuracy) global del 67%. La precisión de la clase 1 (0.72) es superior a la de la clase 0 (0.62), lo que indica que el modelo es más preciso al predecir la clase 1. Sin embargo, la recall para ambas clases está relativamente equilibrada (0.67 para la clase 0 y 0.68 para la clase 1), lo que sugiere que el modelo tiene una tasa moderada de detección de ambas clases. El f1-score también es similar para ambas clases, pero con un margen ligeramente superior para la clase 1. La AUC de 0.76 indica que el modelo tiene una capacidad moderada para distinguir entre las clases, y el Cohen's Kappa de 0.51 sugiere que hay un acuerdo razonable entre las predicciones y las etiquetas reales, pero hay margen de mejora.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino kNN con hiperparametros 2\n","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn_model = KNeighborsClassifier(\n    n_neighbors=7,               # Aumentar el número de vecinos para suavizar las predicciones y reducir el sobreajuste\n    weights='distance',          # Usar ponderación por distancia para dar más importancia a los vecinos más cercanos\n    algorithm='auto',            # Mantener el algoritmo en auto para que el modelo elija el más adecuado\n    leaf_size=40,                # Aumentar el tamaño de la hoja del árbol para mejorar la eficiencia en la búsqueda de vecinos\n    p=2,                         # Mantener la distancia euclidiana (p=2) ya que es efectiva en muchos casos\n    metric='minkowski',          # Continuar usando la métrica Minkowski para la distancia\n    n_jobs=-1                    # Utilizar todos los núcleos de la CPU para acelerar el cómputo\n)\n\n\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:31.712333Z","iopub.execute_input":"2025-03-01T20:58:31.712666Z","iopub.status.idle":"2025-03-01T20:58:31.775192Z","shell.execute_reply.started":"2025-03-01T20:58:31.712641Z","shell.execute_reply":"2025-03-01T20:58:31.774052Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados muestran una mejora significativa respecto a los experimentos anteriores. La precisión y recall para ambas clases han aumentado, especialmente para la clase 1, donde se alcanzan valores de 0.76. El f1-score también ha mejorado considerablemente para ambas clases, alcanzando 0.76 para la clase 1 y 0.70 para la clase 0. La exactitud (accuracy) es del 73%, lo que es un buen indicador de que el modelo tiene un rendimiento global sólido. Más destacable aún es el AUC de 1.0, lo que indica que el modelo tiene una capacidad perfecta para separar las clases. El Cohen's Kappa de 1.0 también sugiere que las predicciones del modelo coinciden perfectamente con las etiquetas reales, lo que es un excelente resultado.","metadata":{}},{"cell_type":"markdown","source":"## Calidad del Vino kNN con hiperparametros 3\n","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = wine.drop([\"quality\"], axis=1)\ny = wine[\"quality\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn_model = KNeighborsClassifier(\n    n_neighbors=5,               # Reducción a 5 vecinos para evitar el sobreajuste y balancear mejor las clases\n    weights='distance',          # Mantener ponderación por distancia para enfatizar los vecinos más cercanos\n    algorithm='auto',            # El algoritmo sigue siendo 'auto' para elegir el más eficiente\n    leaf_size=30,                # Tamaño de hoja del árbol ajustado para mantener un balance entre velocidad y precisión\n    p=1,                         # Cambiar a distancia Manhattan (p=1), lo cual puede mejorar el rendimiento en algunos datos\n    metric='minkowski',          # Continuar con la métrica Minkowski, ya que es versátil y generalmente efectiva\n    n_jobs=-1                    # Mantener el uso de todos los núcleos disponibles para acelerar los cálculos\n)\n\nmodelo = \"k-Nearest Neighbors\"\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:31.776316Z","iopub.execute_input":"2025-03-01T20:58:31.776700Z","iopub.status.idle":"2025-03-01T20:58:31.839589Z","shell.execute_reply.started":"2025-03-01T20:58:31.776664Z","shell.execute_reply":"2025-03-01T20:58:31.838420Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados muestran un rendimiento excelente del modelo k-NN. La precisión y recall para ambas clases son muy buenas, con un aumento en el f1-score de la clase 1 (0.77) y una ligera mejora en la clase 0 (0.70). La exactitud (accuracy) global es del 74%, lo que refleja un buen balance entre la capacidad del modelo para clasificar correctamente ambas clases. El AUC de 1.0 indica que el modelo tiene una separación perfecta entre las clases, lo que significa que es capaz de distinguir sin error entre las dos clases. Además, el Cohen's Kappa de 1.0 confirma que las predicciones son prácticamente perfectas y que hay un acuerdo total entre las predicciones del modelo y las etiquetas reales. En resumen, el modelo está funcionando de manera óptima en este conjunto de datos, logrando una excelente capacidad de clasificación.","metadata":{}},{"cell_type":"code","source":"data = {'fixed acidity': ([10.35253554,  7.26347495,  6.67898833, 12.19280472, 13.38056873,\n        11.55031192, 14.06472709, 11.6747519 , 13.20290934,  9.2585812 ]),\n        'volatile acidity': ([0.12494187, 0.93639711, 0.60643566, 0.8658896 , 0.48623281,\n        0.73974801, 0.87882902, 0.48436769, 0.9797959 , 0.68827086]),\n        'citric acid': ([0.22042425, 0.02174948, 0.66092244, 0.21206596, 0.26902823,\n        0.79488973, 0.05962322, 0.33986682, 0.56810277, 0.6550574 ]),\n        'residual sugar': ([ 9.97329302, 11.46712616, 19.59321475, 15.21857218, 19.9362865 ,\n        18.29606054, 18.60545566,  2.16459   ,  0.49073062,  4.99290913]),\n        'chlorides': ([0.01276844, 0.02554124, 0.08449844, 0.09391178, 0.08946256,\n        0.01140122, 0.03637004, 0.08003057, 0.05379014, 0.08017591]),\n        'free sulfur dioxide': ([47, 19, 37, 37,  4, 10, 48,  1,  9, 43]),\n        'total sulfur dioxide': ([91, 74, 35, 70, 46, 88, 15, 23, 83, 79]),\n        'density': ([1.04725638, 1.02393862, 1.03270583, 1.04728879, 1.00306102,\n        1.01175424, 1.0054896 , 0.98394179, 0.98215251, 1.00903544]),\n        'pH': ([2.60416364, 2.74681535, 2.73456048, 3.0179527 , 3.45726089,\n        3.10749114, 2.766903  , 2.63933977, 2.95081405, 3.37045817]),\n        'sulphates': ([0.87631514, 0.51598346, 0.79518658, 0.66021614, 0.62282499,\n        0.32949315, 0.57303068, 0.32104167, 0.76850822, 0.78956107]),\n        'alcohol': ([ 8.42640967,  9.62703237, 13.70056614,  9.44443614, 11.41589419,\n        9.26896253,  9.24523951,  8.5906224 , 11.15167205, 11.59417586])}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = knn_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:31.840808Z","iopub.execute_input":"2025-03-01T20:58:31.841432Z","iopub.status.idle":"2025-03-01T20:58:31.876533Z","shell.execute_reply.started":"2025-03-01T20:58:31.841387Z","shell.execute_reply":"2025-03-01T20:58:31.875430Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cancer de mama kNN con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN con hiperparámetros\nknn_model = KNeighborsClassifier(\n    n_neighbors=7,               # Número de vecinos a considerar para la clasificación (aumentar para mayor generalización)\n    weights='distance',          # Usar ponderación por distancia para dar más importancia a los vecinos cercanos\n    algorithm='auto',            # El algoritmo 'auto' selecciona el más eficiente en función del tamaño de los datos\n    leaf_size=30,                # Tamaño de la hoja en el árbol de decisión, ajustado para balancear precisión y velocidad\n    p=2,                         # Usar la distancia euclidiana (p=2), que generalmente funciona bien en la mayoría de los casos\n    metric='minkowski',          # Usar la métrica Minkowski para la distancia, que es general y efectiva\n    n_jobs=-1                    # Utilizar todos los núcleos del procesador para acelerar los cálculos\n)\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:31.877317Z","iopub.execute_input":"2025-03-01T20:58:31.877648Z","iopub.status.idle":"2025-03-01T20:58:32.077073Z","shell.execute_reply.started":"2025-03-01T20:58:31.877622Z","shell.execute_reply":"2025-03-01T20:58:32.075984Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados del modelo k-NN muestran un excelente rendimiento en la clasificación, con una exactitud (accuracy) global del 94%. La precisión y recall para ambas clases son muy altas, especialmente para la clase 0 (0.96 de precisión y 0.94 de recall), lo que indica que el modelo clasifica correctamente la mayoría de los casos. La clase 1 también tiene un rendimiento sólido (0.91 de precisión y 0.93 de recall). El f1-score también refleja un buen equilibrio entre precisión y recall para ambas clases. Lo más destacado es que el AUC es 1.0, lo que sugiere que el modelo tiene una capacidad perfecta para distinguir entre las clases. Además, el Cohen's Kappa de 1.0 confirma que las predicciones del modelo coinciden perfectamente con las etiquetas reales, lo que indica un modelo altamente eficiente. En general, los resultados son sobresalientes.","metadata":{}},{"cell_type":"markdown","source":"## Cancer de mama kNN con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn_model = KNeighborsClassifier(\n    n_neighbors=5,               # Reducir a 5 vecinos para evitar el sobreajuste, lo cual mejora la generalización\n    weights='distance',          # Usar ponderación por distancia para dar más importancia a los vecinos cercanos\n    algorithm='ball_tree',       # Cambiar el algoritmo a Ball Tree, que puede ser más eficiente para grandes conjuntos de datos\n    leaf_size=40,                # Ajustar el tamaño de la hoja para optimizar la eficiencia de búsqueda\n    p=1,                         # Cambiar a distancia Manhattan (p=1), que a veces mejora la precisión en datos no lineales\n    metric='minkowski',          # Mantener la métrica Minkowski, que es flexible y efectiva para distancias\n    n_jobs=-1                    # Utilizar todos los núcleos disponibles para acelerar el entrenamiento\n)\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.079849Z","iopub.execute_input":"2025-03-01T20:58:32.080197Z","iopub.status.idle":"2025-03-01T20:58:32.149701Z","shell.execute_reply.started":"2025-03-01T20:58:32.080168Z","shell.execute_reply":"2025-03-01T20:58:32.148221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados del modelo k-NN son excelentes, con una exactitud (accuracy) de 96%, lo que indica que el modelo está clasificando correctamente la gran mayoría de los casos. La precisión y recall para ambas clases son muy altas, con la clase 0 alcanzando una precisión de 0.96 y un recall de 0.97, lo que muestra que el modelo tiene un rendimiento muy bueno en la identificación de esta clase. La clase 1, aunque ligeramente por debajo, tiene un f1-score de 0.94, lo cual sigue siendo excelente. Además, el AUC de 1.0 confirma que el modelo tiene una capacidad perfecta para distinguir entre las dos clases, mientras que el Cohen's Kappa de 1.0 indica que no hay diferencias significativas entre las predicciones del modelo y las etiquetas reales. En resumen, el modelo está funcionando de manera sobresaliente, proporcionando resultados de clasificación muy precisos y robustos.","metadata":{}},{"cell_type":"markdown","source":"## Cancer de mama kNN con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = cancer.drop([\"y\"], axis=1)\ny = cancer[\"y\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn_model = KNeighborsClassifier(\n    n_neighbors=3,               # Reducir el número de vecinos a 3 para mayor flexibilidad y evitar el sobreajuste\n    weights='uniform',           # Usar ponderación uniforme, donde todos los vecinos tienen el mismo peso\n    algorithm='kd_tree',         # Utilizar el algoritmo KD Tree, que es eficiente en conjuntos de datos más grandes\n    leaf_size=25,                # Ajustar el tamaño de la hoja para equilibrar precisión y velocidad\n    p=2,                         # Mantener la distancia euclidiana (p=2), que generalmente funciona bien en muchas situaciones\n    metric='minkowski',          # Seguir utilizando la métrica Minkowski, que es común para la mayoría de los casos\n    n_jobs=-1                    # Utilizar todos los núcleos del procesador para mejorar la eficiencia\n)\n\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.150672Z","iopub.execute_input":"2025-03-01T20:58:32.151119Z","iopub.status.idle":"2025-03-01T20:58:32.276539Z","shell.execute_reply.started":"2025-03-01T20:58:32.151084Z","shell.execute_reply":"2025-03-01T20:58:32.275058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Los resultados del modelo k-NN muestran un rendimiento sólido, con una **exactitud (accuracy)** del 95%, lo que indica que el modelo está clasificando correctamente la mayoría de los casos. Las métricas de **precisión** y **recall** son bastante buenas para ambas clases, con la clase 0 obteniendo una precisión de 0.96 y un recall de 0.96, mientras que la clase 1 tiene una precisión y recall de 0.93. El **f1-score** también refleja un buen equilibrio entre precisión y recall. Sin embargo, el **AUC** de 0.94 es ligeramente inferior a 1.0, lo que sugiere que, aunque el modelo distingue bien entre las clases, hay algo de margen para mejorar en la capacidad de discriminación. El **Cohen's Kappa** de 0.90 es alto, lo que indica una buena concordancia entre las predicciones del modelo y las etiquetas reales. En general, el modelo tiene un buen desempeño, pero siempre puede haber espacio para mejorar.","metadata":{}},{"cell_type":"code","source":"data = {\n    \"x.radius_mean\": [14.0, 15.5, 13.2, 14.5, 15.0, 13.8, 14.2, 16.1, 15.3, 14.6],\n    \"x.texture_mean\": [19.0, 20.3, 18.5, 17.2, 21.1, 20.0, 18.8, 19.5, 20.2, 19.3],\n    \"x.perimeter_mean\": [85.0, 90.5, 80.3, 84.6, 89.7, 82.1, 86.4, 88.9, 87.5, 85.3],\n    \"x.area_mean\": [500.0, 550.2, 480.5, 510.6, 545.0, 495.0, 520.1, 530.4, 515.3, 505.2],\n    \"x.smoothness_mean\": [0.1, 0.12, 0.09, 0.11, 0.1, 0.08, 0.1, 0.13, 0.12, 0.1],\n    \"x.compactness_mean\": [0.02, 0.03, 0.025, 0.021, 0.03, 0.015, 0.02, 0.03, 0.02, 0.022],\n    \"x.concavity_mean\": [0.05, 0.07, 0.06, 0.055, 0.065, 0.045, 0.05, 0.06, 0.055, 0.05],\n    \"x.concave_pts_mean\": [0.03, 0.035, 0.02, 0.04, 0.03, 0.025, 0.03, 0.03, 0.025, 0.03],\n    \"x.symmetry_mean\": [0.18, 0.2, 0.17, 0.19, 0.18, 0.17, 0.18, 0.21, 0.19, 0.18],\n    \"x.fractal_dim_mean\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.046, 0.047, 0.05, 0.048, 0.05],\n    \"x.radius_se\": [0.03, 0.04, 0.02, 0.03, 0.04, 0.02, 0.03, 0.02, 0.03, 0.04],\n    \"x.texture_se\": [0.04, 0.05, 0.03, 0.04, 0.05, 0.03, 0.04, 0.03, 0.05, 0.04],\n    \"x.perimeter_se\": [0.12, 0.13, 0.1, 0.11, 0.12, 0.09, 0.11, 0.12, 0.1, 0.11],\n    \"x.area_se\": [30.0, 35.2, 28.5, 32.1, 33.5, 29.3, 30.2, 31.6, 32.8, 30.5],\n    \"x.smoothness_se\": [0.002, 0.0025, 0.0018, 0.0022, 0.002, 0.0019, 0.0021, 0.0023, 0.0021, 0.002],\n    \"x.compactness_se\": [0.001, 0.0015, 0.0012, 0.0011, 0.0013, 0.001, 0.0011, 0.0013, 0.0012, 0.0011],\n    \"x.concavity_se\": [0.0025, 0.003, 0.0027, 0.0026, 0.0031, 0.0023, 0.0025, 0.0028, 0.0026, 0.0027],\n    \"x.concave_pts_se\": [0.001, 0.0012, 0.0009, 0.001, 0.0011, 0.0008, 0.001, 0.0011, 0.001, 0.0009],\n    \"x.symmetry_se\": [0.008, 0.01, 0.009, 0.0085, 0.009, 0.008, 0.0085, 0.009, 0.0087, 0.008],\n    \"x.fractal_dim_se\": [0.003, 0.0035, 0.0028, 0.0032, 0.0031, 0.0029, 0.003, 0.0031, 0.0032, 0.003],\n    \"x.radius_worst\": [17.0, 18.5, 16.5, 17.8, 18.3, 16.9, 17.4, 18.7, 17.9, 17.2],\n    \"x.texture_worst\": [22.0, 23.3, 21.8, 22.5, 23.1, 22.3, 21.9, 23.0, 22.8, 22.1],\n    \"x.perimeter_worst\": [110.0, 120.3, 115.2, 113.5, 119.4, 114.6, 117.5, 120.0, 118.2, 115.8],\n    \"x.area_worst\": [800.0, 850.5, 780.3, 800.2, 830.0, 790.1, 810.5, 830.4, 820.2, 800.5],\n    \"x.smoothness_worst\": [0.13, 0.14, 0.12, 0.13, 0.14, 0.13, 0.13, 0.14, 0.13, 0.12],\n    \"x.compactness_worst\": [0.03, 0.035, 0.031, 0.028, 0.032, 0.03, 0.029, 0.031, 0.03, 0.029],\n    \"x.concavity_worst\": [0.07, 0.08, 0.075, 0.071, 0.078, 0.073, 0.074, 0.079, 0.076, 0.075],\n    \"x.concave_pts_worst\": [0.05, 0.06, 0.045, 0.048, 0.055, 0.04, 0.045, 0.06, 0.048, 0.05],\n    \"x.symmetry_worst\": [0.22, 0.23, 0.21, 0.22, 0.23, 0.22, 0.21, 0.22, 0.22, 0.21],\n    \"x.fractal_dim_worst\": [0.05, 0.06, 0.048, 0.05, 0.055, 0.051, 0.052, 0.05, 0.053, 0.054]\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = knn_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.277985Z","iopub.execute_input":"2025-03-01T20:58:32.278437Z","iopub.status.idle":"2025-03-01T20:58:32.339690Z","shell.execute_reply.started":"2025-03-01T20:58:32.278401Z","shell.execute_reply":"2025-03-01T20:58:32.336912Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diabetes kNN con hiperparametros 1","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Crear el modelo k-NN con hiperparámetros\nknn_model = KNeighborsClassifier(\n    n_neighbors=5,              # Número de vecinos a considerar para la predicción (valor ajustable)\n    weights='distance',         # Ponderar los vecinos por la distancia, donde los más cercanos tienen mayor peso\n    algorithm='auto',           # Determina el algoritmo a usar para la búsqueda de los vecinos.\n    leaf_size=30,               # Tamaño de la hoja del árbol\n    p=2,                        # La métrica de distancia a utilizar (p=2 para distancia euclidiana)\n    metric='minkowski',         # Usar la distancia de Minkowski, que es la más común para k-NN\n    n_jobs=-1                   # Usar todos los núcleos disponibles para paralelizar el entrenamiento y predicción\n)\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.340717Z","iopub.execute_input":"2025-03-01T20:58:32.341254Z","iopub.status.idle":"2025-03-01T20:58:32.424023Z","shell.execute_reply.started":"2025-03-01T20:58:32.341212Z","shell.execute_reply":"2025-03-01T20:58:32.422610Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo k-NN muestra un rendimiento decente, pero con margen de mejora. La exactitud (accuracy) es del 67%, lo que indica que el modelo no está logrando una clasificación perfecta. Aunque la clase 0 tiene buenos resultados con una precisión de 0.76 y un recall de 0.72, la clase 1 tiene un rendimiento inferior con una precisión de 0.53 y recall de 0.58, lo que sugiere que el modelo tiene dificultades para clasificar correctamente la clase minoritaria. La AUC de 1.0 indica que el modelo tiene una capacidad perfecta para distinguir entre las clases, pero esto podría reflejar un sesgo en el conjunto de datos o en la evaluación. El Cohen's Kappa también es 1.0, lo que indica que las predicciones del modelo son perfectamente consistentes con las etiquetas reales, pero esto podría ser un indicio de sobreajuste o de un desbalance en las clases.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes kNN con hiperparametros 2","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn_model = KNeighborsClassifier(\n    n_neighbors=7,              # Aumentar el número de vecinos para suavizar las predicciones y mejorar la robustez del modelo\n    weights='distance',         # Usar ponderación por distancia, para que los vecinos más cercanos influyan más en la predicción\n    algorithm='auto',           # Dejar que el modelo seleccione automáticamente el mejor algoritmo para la búsqueda de vecinos\n    leaf_size=25,               # Ajustar el tamaño de la hoja para equilibrar la velocidad y la precisión\n    p=2,                        # Mantener la distancia euclidiana (p=2) para una métrica estándar de clasificación\n    metric='minkowski',         # Usar la distancia de Minkowski, que es una generalización de otras métricas\n    n_jobs=-1,                  # Usar todos los núcleos de CPU para acelerar el entrenamiento y las predicciones\n)\n\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.425544Z","iopub.execute_input":"2025-03-01T20:58:32.425963Z","iopub.status.idle":"2025-03-01T20:58:32.502737Z","shell.execute_reply.started":"2025-03-01T20:58:32.425926Z","shell.execute_reply":"2025-03-01T20:58:32.501444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo k-NN sigue mostrando un rendimiento desigual entre las clases. La exactitud general es del 68%, lo que indica que el modelo tiene una capacidad limitada para clasificar correctamente todas las muestras. Aunque la clase 0 tiene un buen recall de 0.74, la clase 1 sigue mostrando un rendimiento inferior con un recall de 0.58 y una precisión de 0.55. Aunque la AUC de 1.0 sugiere que el modelo es capaz de distinguir perfectamente entre las clases en términos de probabilidades, los resultados de precisión y recall sugieren que el modelo está sufriendo de un desbalance entre las clases. El Cohen's Kappa también es 1.0, lo que generalmente indica que el modelo tiene un buen desempeño, pero esto puede ser engañoso debido a que no está penalizando adecuadamente los desbalances de clase.","metadata":{}},{"cell_type":"markdown","source":"## Diabetes kNN con hiperparametros 3","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Configurar semillas para reproducibilidad\nnp.random.seed(5)\ntf.random.set_seed(5)\nrandom.seed(5)\n\n# Preparar datos\nX = diabetes.drop([\"Outcome\"], axis=1)\ny = diabetes[\"Outcome\"]\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nknn_model = KNeighborsClassifier(\n    n_neighbors=9,              # Aumentar ligeramente el número de vecinos para mejorar la estabilidad del modelo\n    weights='distance',         # Usar ponderación por distancia para que los vecinos más cercanos influyan más en la predicción\n    algorithm='auto',           # Dejar que el modelo seleccione automáticamente el mejor algoritmo de búsqueda\n    leaf_size=20,               # Ajustar el tamaño de la hoja para equilibrar velocidad y precisión\n    p=2,                        # Mantener la distancia Euclidiana (p=2) para la métrica estándar de clasificación\n    metric='minkowski',         # Usar la distancia de Minkowski para generalizar la métrica de distancia\n    n_jobs=-1,                  # Utilizar todos los núcleos disponibles para acelerar el entrenamiento y predicción\n)\n\n\n\n# Entrenar el modelo\nknn_model.fit(X_train, y_train)\n\n# Realizar predicciones\ny_train_knn = knn_model.predict(X_train)\ny_test_knn = knn_model.predict(X_test)\n\n# Evaluar el rendimiento del modelo\nprint(metrics.classification_report(y_test, y_test_knn))\n\nauc = roc_auc_score(y_train, y_train_knn)\nprint(f\"AUC: {auc}\")\n\nkappa = cohen_kappa_score(y_train, y_train_knn)\nprint(f\"Cohen's Kappa: {kappa}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.503840Z","iopub.execute_input":"2025-03-01T20:58:32.504226Z","iopub.status.idle":"2025-03-01T20:58:32.579524Z","shell.execute_reply.started":"2025-03-01T20:58:32.504190Z","shell.execute_reply":"2025-03-01T20:58:32.578163Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"El modelo k-NN sigue mostrando un buen desempeño en términos de **AUC** (1.0) y **Cohen's Kappa** (1.0), lo que indica que tiene una excelente capacidad para distinguir entre las clases. Sin embargo, la **precisión** y **recall** siguen siendo desiguales entre las clases. La clase 0 tiene un buen rendimiento con un **recall** de 0.77, mientras que la clase 1 sigue mostrando un desempeño más bajo con un **recall** de 0.65 y una **precisión** de 0.61. Aunque el modelo muestra una **exactitud** del 73%, esto refleja una capacidad insuficiente para clasificar correctamente la clase minoritaria (1).","metadata":{}},{"cell_type":"code","source":"data = {\n    \"Pregnancies\": [6, 14, 10, 7, 6, 10, 10, 3, 7, 2],\n    \"Glucose\": [122, 71, 157, 107, 199, 90, 127, 91, 158, 118],\n    \"BloodPressure\": [108, 91, 109, 64, 111, 111, 96, 111, 100, 104],\n    \"SkinThickness\": [12, 46, 16, 30, 18, 48, 27, 13, 34, 23],\n    \"Insulin\": [261, 796, 365, 584, 359, 111, 386, 474, 447, 528],\n    \"BMI\": [40.50, 22.68, 28.56, 22.92, 38.39, 29.48, 23.61, 33.33, 18.85, 40.74],\n    \"DiabetesPedigreeFunction\": [0.90, 0.79, 1.85, 1.45, 0.65, 1.14, 1.04, 1.92, 1.69, 1.49],\n    \"Age\": [67, 44, 46, 45, 65, 61, 49, 35, 65, 21],\n}\n\n# Crear el DataFrame correctamente\ndf = pd.DataFrame(data)\n\n# Realizar las predicciones\nrandom_predictions = knn_model.predict(df)\n\n# Mostrar las predicciones\nprint(\"Predicciones aleatorias:\")\nrandom_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T20:58:32.580929Z","iopub.execute_input":"2025-03-01T20:58:32.581385Z","iopub.status.idle":"2025-03-01T20:58:32.622358Z","shell.execute_reply.started":"2025-03-01T20:58:32.581348Z","shell.execute_reply":"2025-03-01T20:58:32.620789Z"}},"outputs":[],"execution_count":null}]}